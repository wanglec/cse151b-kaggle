{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./new_train/new_train\"\n",
    "test_path = \"./new_val_in/new_val_in\"\n",
    "submission_path = \"./sample_submission.csv\"\n",
    "submission_dir = \"./submissions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Val Split\n",
    "TRAIN_SIZE = 0.95\n",
    "VAL_SIZE = 0.05\n",
    "\n",
    "# training config\n",
    "NUM_EPOCH = 30\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-3\n",
    "EARLY_STOP_MAX = 6\n",
    "\n",
    "# feature engineering configs\n",
    "NEARBY_DISTANCE_THRESHOLD = 50.0  # Distance threshold to call a track as neighbor\n",
    "DEFAULT_MIN_DIST_FRONT_AND_BACK = 100. # default distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import plot_trajectory\n",
    "\n",
    "import optuna\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from argoverse_forecasting.utils.social_features_utils import SocialFeaturesUtils\n",
    "from argoverse_forecasting.utils import baseline_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseTrainDataset(Dataset):\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseTrainDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "        self.p = []\n",
    "        self.v = []\n",
    "        for pkl_path in tqdm(self.pkl_list):\n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "\n",
    "            if self.transform:\n",
    "                data = self.transform(data)\n",
    "                \n",
    "            agent_idx = np.where(data[\"agent_id\"] == np.unique(data[\"track_id\"].flatten()))[0][0]\n",
    "            self.p.append(np.concatenate([data['p_in'][agent_idx], data['p_out'][agent_idx]], axis=0))\n",
    "            self.v.append(np.concatenate([data['v_in'][agent_idx], data['v_out'][agent_idx]], axis=0))\n",
    "        \n",
    "#         self.inp = np.concatenate(self.inp, axis=0)\n",
    "#         self.out = np.concatenate(self.out, axis=0)\n",
    "#         shuffler = np.random.permutation(len(self.inp))\n",
    "#         self.inp, self.out = self.inp[shuffler], self.out[shuffler]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return  [self.p[idx], self.v[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205942/205942 [17:26<00:00, 196.77it/s]  \n"
     ]
    }
   ],
   "source": [
    "train = ArgoverseTrainDataset(data_path=train_path)\n",
    "test = ArgoverseDataset(data_path=test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(TRAIN_SIZE * len(train))\n",
    "val_size = len(train) - train_size\n",
    "train, val = torch.utils.data.random_split(train, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_track(scene, mode=\"train\"):\n",
    "    agent_idx = np.where(scene[\"agent_id\"] == np.unique(scene[\"track_id\"].flatten()))[0][0]\n",
    "    agent_traj = scene['p_in'][agent_idx]\n",
    "    if mode == \"test\":\n",
    "        return agent_traj\n",
    "    else:\n",
    "        agent_traj = np.concatenate([agent_traj, scene['p_out'][agent_idx]])\n",
    "    return agent_traj\n",
    "\n",
    "def get_social_tracks(scene, mode=\"train\"):\n",
    "    agent_idx = np.where(scene[\"agent_id\"] == np.unique(scene[\"track_id\"].flatten()))[0][0]\n",
    "    social_masks = scene[\"car_mask\"].flatten()\n",
    "    social_masks[agent_idx] = 0\n",
    "    social_trajs = scene['p_in'][social_masks.astype(bool)]\n",
    "    \n",
    "    if mode == \"test\":\n",
    "        return social_trajs\n",
    "    else:\n",
    "        return np.concatenate([social_trajs, scene['p_out'][social_masks.astype(bool)]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate social features\n",
    "def get_social_features(scene, mode=\"train\"):\n",
    "    \"\"\"\n",
    "    Extract social features:\n",
    "        1. number of neighbors\n",
    "        2. min front/back distance at each timestamp\n",
    "    \"\"\"\n",
    "    agent_track = get_agent_track(scene, mode)\n",
    "    social_tracks = get_social_tracks(scene, mode)\n",
    "    # compute social features\n",
    "    num_neighbors = count_num_neighbors(agent_track[:19], social_tracks[:, :19])\n",
    "#     social_features_utils = SocialFeaturesUtils()\n",
    "#     min_dist_front_back = social_features_utils.get_min_distance_front_and_back(\n",
    "#         agent_track=agent_track,\n",
    "#         social_tracks=social_tracks,\n",
    "#         obs_len=19,\n",
    "#         raw_data_format={\"X\": 0, \"Y\": 1}\n",
    "#     )\n",
    "#     min_dist_front_back = 1 - (min_dist_front_back / DEFAULT_MIN_DIST_FRONT_AND_BACK)\n",
    "    \n",
    "#     return np.concatenate((num_neighbors, min_dist_front_back), axis=1)\n",
    "    return num_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_num_neighbors(agent_traj, social_trajs):\n",
    "    \"\"\"\n",
    "    Calculate euclidean distance between agent_traj and social_trajs\n",
    "    if distance is less than NEARBY_DISTANCE_THRESHOLD, then num_neighbors++\n",
    "    \n",
    "    Args:\n",
    "        agent_traj (np.array): data for agent trajectory\n",
    "        social_trajs (np.array): array of other agents' trajectories\n",
    "    Returns:\n",
    "        (np.array): \n",
    "    \"\"\"\n",
    "    num_neighbors = []\n",
    "    dist = np.sqrt(\n",
    "        (social_trajs[:, :, 0] - agent_traj[:, 0])**2 \n",
    "        + (social_trajs[:, :, 1] - agent_traj[:, 1])**2\n",
    "    ).T\n",
    "    num_neighbors = np.sum(dist < NEARBY_DISTANCE_THRESHOLD, axis=1)\n",
    "    return num_neighbors.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_collate(batch):\n",
    "#     \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "#     inp, out = [], []\n",
    "#     for scene in batch:\n",
    "#         agent_idx = np.where(scene[\"agent_id\"] == np.unique(scene[\"track_id\"].flatten()))[0][0]\n",
    "#         social_features = get_social_features(scene)\n",
    "#         inp.append(np.hstack([scene['p_in'][agent_idx], scene['v_in'][agent_idx], social_features])) # \n",
    "#         out.append(scene['p_out'][agent_idx])\n",
    "\n",
    "#     inp = torch.FloatTensor(inp)\n",
    "#     out = torch.FloatTensor(out)\n",
    "#     return [inp, out]\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp, out = [], []\n",
    "    for data in batch:\n",
    "        p, v = data\n",
    "        inp.append(np.concatenate([p[:19, :], v[:19, :]], axis=1))\n",
    "        out.append(p[19:, :])\n",
    "    \n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.FloatTensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "def my_test_collect(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp, out = [], []\n",
    "    for scene in batch:\n",
    "        agent_idx = np.where(scene[\"agent_id\"] == np.unique(scene[\"track_id\"].flatten()))[0][0]\n",
    "#         social_features = get_social_features(scene, mode=\"test\")\n",
    "        inp.append(np.hstack([scene['p_in'][agent_idx], scene['v_in'][agent_idx]])) # social_features\n",
    "        out.append([])\n",
    "\n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.FloatTensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle = True, collate_fn=my_collate, num_workers=0)\n",
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle = True, collate_fn=my_collate, num_workers=0)\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE, shuffle = False, collate_fn=my_test_collect, num_workers=0)\n",
    "# exmaple = iter(train_loader)\n",
    "# exmaple.next()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = iter(train_loader)\n",
    "train_example = train_0.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v51</th>\n",
       "      <th>v52</th>\n",
       "      <th>v53</th>\n",
       "      <th>v54</th>\n",
       "      <th>v55</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58</th>\n",
       "      <th>v59</th>\n",
       "      <th>v60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>9897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>9905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>9910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>9918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID   v1   v2   v3   v4   v5   v6   v7   v8   v9  ...  v51  v52  v53  \\\n",
       "0     10002  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1     10015  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2     10019  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3     10028  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      1003  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "3195   9897  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3196     99  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3197   9905  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3198   9910  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3199   9918  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "      v54  v55  v56  v57  v58  v59  v60  \n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "3195  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3196  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3197  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3198  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3199  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[3200 rows x 61 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(submission_path)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_features_utils = SocialFeaturesUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = train[1]\n",
    "agent_track = get_agent_track(train_0)\n",
    "social_trajs = get_social_tracks(train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(social_trajs.reshape(49, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23.52509836, 100.        ],\n",
       "       [ 23.88654848, 100.        ],\n",
       "       [ 21.82572515, 100.        ],\n",
       "       [ 21.09440706, 100.        ],\n",
       "       [ 20.15324459, 100.        ],\n",
       "       [ 19.35958392, 100.        ],\n",
       "       [ 18.79744729, 100.        ],\n",
       "       [ 16.72545819, 100.        ],\n",
       "       [ 15.95265334, 100.        ],\n",
       "       [ 15.46044607, 100.        ],\n",
       "       [ 14.05003934, 100.        ],\n",
       "       [ 13.45318307, 100.        ],\n",
       "       [ 12.44119391, 100.        ],\n",
       "       [ 11.90284912, 100.        ],\n",
       "       [ 11.16732128, 100.        ],\n",
       "       [ 10.26514381, 100.        ],\n",
       "       [  9.53765407, 100.        ],\n",
       "       [  8.60715376, 100.        ],\n",
       "       [  7.76863007, 100.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social_features_utils.get_min_distance_front_and_back(\n",
    "    agent_track=agent_track,\n",
    "    social_tracks=social_trajs,\n",
    "    obs_len=19,\n",
    "    raw_data_format={\"X\": 0, \"Y\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = train[8]\n",
    "agent_track = get_agent_track(train_0)\n",
    "social_trajs = get_social_tracks(train_0)\n",
    "# train_1 = train[11]\n",
    "# agent_track = get_agent_track(train_1)\n",
    "# social_trajs = get_social_tracks(train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_traj, translation, rotation = baseline_utils.get_normalized_traj(\n",
    "    np.concatenate([[agent_track], social_trajs]), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent_id = 0\n",
    "agent_id_2 = 2\n",
    "plt.scatter(normalized_traj[agent_id][:, 0], normalized_traj[agent_id][:, 1])\n",
    "plt.scatter(normalized_traj[agent_id_2][:, 0], normalized_traj[agent_id_2][:, 1])\n",
    "plt.yticks(range(-3, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAdiUlEQVR4nO3df7BV5Xkv8O+X7TnXY01AAio/zilOw9g6QiWeCh3yh1VRoyhnkpbIjfdiJy3ttPeaxFuT45XxB0MnZ7SDqTfJJFQd6WBx6GiOFE0NYpxebCCcEwyYGopNWuCAguGCVU4CHJ77x17n12attff6sfdae73fz4yz91p7sdc6G3z2Os/7vM9LM4OIiBTfhKwvQEREGkMBX0TEEQr4IiKOUMAXEXGEAr6IiCPOy/oCwkyZMsVmzZqV9WWIiDSN/v7+98xsqt9ruQ74s2bNQl9fX9aXISLSNEj+R9BrSumIiDhCAV9ExBEK+CIijlDAFxFxhAK+iIgjFPDrYfdG4LErgYcmlR93b8z6ikRE8l2W2ZR2bwT+4W7g9GB5+8SB8jYAzF2a3XWJiPN0h5+2ratGg/2w04Pl/SIiGUol4JO8meRekm+T7PZ5/TdJ/oDkr0j+RRrnzK0TB6PtFxFpkMQBn2QJwDcAfArAFQCWkbyi4rBjAO4G8FdJz5d7E2dG2y8i0iBp3OFfA+BtM/uZmZ0C8CyAJWMPMLMjZrYTwOkUzpdv1z8AtLSN39fSVt4vIpKhNAL+DAAHxmwf9Pa5ae5S4LbHgYntAFh+vO1xDdiKSObSqNKhz77YC+WSXAFgBQB0dHTEfZtszV2qAC8iuZPGHf5BAO1jtmcCOBT3zcxsrZl1mlnn1Km+HT5FRCSGNAL+TgCzSV5GshXAHQA2pfC+xaRJWSKSkcQpHTM7Q/J/AHgZQAnAU2b2E5J/6r3+LZKXAugD8FEAZ0l+EcAVZvZ+0vM3FU3KEpEMpTLT1sxeAvBSxb5vjXn+DsqpnmLZvbE8oerEwXLZ5fUPhAfuapOyoryXiEhEaq0QV5y79cBJWQd05y8idafWCnHFaaEQNPmKJbVjEJG6U8CPK04LhaBJWTYU/b1ERCJSwI8rTguFoElZE9v9j1c7BhFJkXL4cV3/wPi8O1BbC4WgSVlx3ktEJALd4ceVZgsFtWMQkQagWewuCHXX2dlpfX19WV+GiEjTINlvZp1+r+kOX0TEEQr41agVgogUhAZtw6gVgogUiO7ww2h9WhEpEAX8MM2wPq1STiJSI7dSOpvvAfqfLs9sZQm4+i5g8Zrg4yfOLKdx/PbnQdopp6jN4ESkqbhzh7/5HqDvydE2BjZU3t58T/Cfyfv6tGmmnIa/PE4cAGCjXx76jUGkMNwJ+P1PR9sP5H9CVJopJ41XiBSeOymdoAZlQfuH5WV9Wr90S1jKKWp6phnGK0QkEXfu8FmKtj9PgtIts2/0TznNvjF6eiZOMzgRaSruBPyr74q2P0+C0i37vuefctr3vejpmbyPV4hIYu6kdIarcaJU6eRFWLrFL+X0/Ipo7wOMvoeqdEQKy52AD5SDezME+EpRy0Pj5vb9vjzSLNWMWhYrIqlyJ6XTzKKmW4KOj5rbT7NUM05ZrIikSgG/GUQtDw06PmpuP81SzThlsSKSKrdSOs0sanloGrn9avujpGjilsVGoZnCIqF0h++SqKWXYfujpmjqXRarmcIiVSnguyStsYDrH4ieoql3WaxmCotUlUrAJ3kzyb0k3ybZ7fM6ST7uvb6b5CfSOK+fnZu+jXce+jjOPjgR7zz0cezc9O16nar5pDUWMHdp9BTN4jVA5+dH7+hZKm8HpYBCuoD27hrAwp5XcVn3i1jY8yp6dw1oprBIDRKvaUuyBOBfASwCcBDATgDLzOxfxhxzC4D/CeAWAPMB/LWZza/23lHXtN256du4sn8l2nhqZN+gteLNq1fjd27/k5rfR2rw8GT/4M4S8OCxZO9d2QUUKP9mcdvj6B1aiG3f+Sa+iGcxne/hkE3B13AHVv3ac7hg8PC57zWxHfjSm/7nKHi+v3fXAB59eS8OHR/E9EltuPemy9E1b0bWlyV1Vu81ba8B8LaZ/czMTgF4FsCSimOWAPhbK9sOYBLJaSmce5z2Hz06LtgDQBtPof1Hj6Z9KqlniiYkPfPGi2uximsxc8J7mEBg5oT3sIpr8d1f/nbt6apq+f4a1xjw/U0jJ3p3DeC+5/dg4PggDMDA8UHc9/yeXF2jNF4aAX8GgLGzfA56+6IeAwAguYJkH8m+o0ePRrqQi83/+IvtvUjvIzWImqKJIiQ980en1uOCii/1C3gK84f6/NNPwLnBOyzfX+Pgb94D6qMv78Xg6fG/gQ2eHsKjL+/N6IokD9Ioy6TPvso8US3HlHearQWwFiindKJcyBFOxaU4N+gf4RRcGuWNpDb1mrkcMlN4esCXwfQJvzi3FDVogZjKYD/sxMHgL4PvfmVcCuiNDz+DwdPXjDtsOKDmIW1y6Lj/zxi0X9yQxh3+QQDtY7ZnAjgU45jEDnziXgxa67h9g9aKA5+4N+1TST2FVAf9ss3/q9t3f1DwDioFnTgz+LeLwWPj7vq/fPqbuH3CtnMOy0tAnT6pLdJ+cUMaAX8ngNkkLyPZCuAOAJsqjtkE4L971ToLAJwwM58RtmR+5/Y/wZtXr8Y7mIqzRryDqRqwbUYh1UEXfGoVzpTOH3f4mdL5uOBTPuWXQcHbhoLz/TW2g76Ap/Dl8zbi9gnbsK31bvzsv/xXbGu9G8sv/GFNf77e7r3pcrS1jP9ia2sp4d6bLs/oiiQPElfpACNVOF8DUALwlJn9Jck/BQAz+xZJAvg6gJsBnATwh2ZWtfwmapWOOKLWCpvHrgxIDbWX/4zfe/hVCAU4a8Av0TpuTOFM6Xyct+T/5KLiR1U6bgqr0kkl4NeLAr4kElLeGRqQK79QTn1YTulUOMsJmGBnz/3zQaWgRZN1aWvW58+psICvXjpSXHF7/Fcb/AWAljZMCBv8LbqgAXGgMUE36/M3Kd3hi9TC725y6yrflNHJtmlYZN8sdiolLF3WiN9usj5/jukOH8DK3j3YsOMAhsxQIrFsfjtWd83J+rKkWQR1K6248z9TOh8PfPgZDJwq7xuuzweQetDPNEefdSuLrM/fpJwI+Ct792D99v0j20NmI9sK+hKbT8po9Yefwakzp7Ct9e6R1g+PnFmKR19uTRSMK4P77/3mVDzXPzAyuaqeXyy+oq7CVrTzNyknumVu2OHzDyNkv0jN5i4tpxAeOg586U38v5On0NPyxLjWDz0tT6Dz/S0A4rVj8JvV+8z2/dnOpK2182qNbSrqdn4Zx4mAPxQwThG0XySu+1r/3rf1w32tfx+7HYNfm4Sgf7kNm/hVS+fVeq5RELXzqwBwJKVTIn2De4l+HR+kWeWh7vwS+PdtugTvhfa3CbvOKEG8oTNpq63CFtazKI3AHHUVOHHjDn/Z/PZI+6X5JGlmlmbXSwbkkDlxJjrf3zJuVu5wa4ZqAT0oiFferuRuJq0GVnPHiYC/umsO7lzQMXJHXyJx54IODdgWSLXukEFBPfWul0G55dk3oqf1yXNy+7dP2FZuxxCS5w5qk/C5BR2YMakNBDBjUhu++uk5+Sr/jLp0ptSd6vClEC7rftE3r00Aj332Ktz3/J5xXwhtLSV89dNz8OjLezHgc4c9Y1IbXu++Lt7FRKjZP2YX4qPnncF5Q78c2XfSWvFIy5/hqltXjATwPKSrIos701kSUWsFKbyFPa8GBm4Aga8d8u7sKxHAz3tuTe8CH5oEv6FWg3/v8INnp2CRfSN/d+1Rqf1Bw9V7xSuRzIV1hwzrDd+wNsJBuf2Aw6fzF8VYsKSibLWhwX7zPeWlOB+aWH7cfE/jzp1TCvhSCF3zZuCrn57jm9MOC+oNayMclNtvm+x7+CH7WPkxJ/31m87me4C+J0fXXbah8rbjQd+JssysNGXetYl1zZvh+/nee9Plvjn8sX8fdf97CmrkBpyT5z5prXjkTPn4Qi9YUs90T//TwfvrsUpbk1DAr5Ph6o/Mpr7LiGpBPeiLYlhqX9whdeMnv/sAzj/5Dg7Zx/DImaXYdPaT+SuzTFO9u13aULT9jtCgbZ2EDSLGrv6Qhqv84gZGK3wK1QytUUbu6gPamqTV7fLhyf7BnSXgwXPXNigSdcvMgBaRLoa4s2PjqPabRtOrZTWxtCZlXX1XOWfvt99hGrStEy0iXQz64k6RX6uFSmlNylq8Buj8/OiC9SyVtx3O3wO6w6+bsIFCaR7TJ7X5pub0xR1Dtbt3b0ZyeXGTFAZyF69xPsBXUsCvk4ZVf4zhRA64wYr6xZ3Jv5WgHvZAOXc/+0bgx3+nZQvrSIO2BdHIwUXXZPZFWqeyxcz+rVRrtaBlC1OhQVsHNHJw0TWZDKbWsWwxs38r1RaVV3fNulPAL4hGDC4qZdRAdewln+lAdFgPey1bWHeq0imIelcFpd5GWMLV8W43txVkWraw7hIFfJKTSW4huc97vCjguKdIHiHZlIm4NBfIqJd694Sp1m9eUlbHXvIN6x8UlZYtrLukKZ1uAFvNrIdkt7f9FZ/jngbwdQB/m/B8DVetRUJe0hz1rgpSPXqDXf+A/wBnCne7WVSQ1UzLFtZV0oC/BMC13vN1AF6DT8A3s38iOSvhuTJR7c42T/1y6jm4qHr0Bqs2wJlQ4Wf1iq+kAf8SMzsMAGZ2mOTFSS+I5AoAKwCgo6Mj6dslFnZnm6TaIS+/GdSqXvXoK3v3YMOOAxgyQ4nEsvntWnpymO52o9FiK1VVDfgkXwFwqc9L96d/OYCZrQWwFijX4dfjHFGE3dnGTXM0YyfNeqQBVvbuwfrt+0e2h8xGthX0JZJ6d98siKqDtmZ2g5ld6fPfCwDeJTkNALzHI/W+4EYLG+CKW+3QrAOgXfNm4PXu6/Dznlvxevd1ib+cNuzwn3UZtF8kUFgZq4xIWpa5CcBy7/lyAC8kfL/cCVtJKW61gwZAy4YCZnkH7RcJpElbNUmaw+8BsJHk5wHsB/AHAEByOoAnzOwWb3sDyoO7U0geBPCgmfn0Ls2noAGuuGmOagOgQfn9uHn/vI4XlEjf4F5i0EqvIgE0aasm6qWTgbBeJgB8X/vM1TPwXP9A5P4nee6xU5nDH3bngg7l8INUDkzOvhHY9z0NVFbr0+OQsF46mmmbgbA0UVB+f8OOA7Hy/nkeL1jdNQd3LugYuaMvkQr2YYaD2okDAKz82Pfk+O1/uLt8nGs0aasmusPPmcu6X0SUvxEC+HnPrZHfr9qfkxwK6iZZSd0lnaY7/CYSVOETlNeuVhGU274pEl2tA5AaqJQACvg5E1T5s2x+e6yKoNz2TZHoah2A1EClBFDAz5mg/P7qrjmBef8475f1gK3E4NdNspK6S0oI5fBFmomqdKQKrXglUhTqryMJKKUjIuIIBXwREUco4IuIOEIBX0TEEQr4IiKOUJWOw/LaRVNE6kMB31HNuOqWiCSjlI6j8txFU0TqQwHfUVp1S8Q9CviOUhdNEfco4DtKXTRF3KNBW0eFrcer6h2RYlLAd5jf4uyq3imIyq6a6qIpUEpHKqh6pwD81r51da1bGUcBX8ZR9U4BbF0FnK74+zo9WN4vTlPAl3FUvVMAQWvaaq1b5yngyziq3imAoDVttdat8xIFfJKTSW4huc97vMjnmHaS3yf5FsmfkPxCknNKfWkN3ALwW/tWa90KEq5pS/IRAMfMrIdkN4CLzOwrFcdMAzDNzH5E8iMA+gF0mdm/VHt/rWkrEpOqdFLVTKXK9VzTdgmAa73n6wC8BmBcwDezwwAOe8//k+RbAGYAqBrwRSQmrX2bmiKVKifN4V/iBfThwH5x2MEkZwGYB2BHyDErSPaR7Dt69GjCyxMRSaZIpcpV7/BJvgLgUp+X7o9yIpIXAngOwBfN7P2g48xsLYC1QDmlE+UcIiJpK1KpctWAb2Y3BL1G8l2S08zssJerPxJwXAvKwf4ZM3s+9tWKiDTY9EltGPAJ7s1Yqpw0pbMJwHLv+XIAL1QeQJIAngTwlpmtSXg+EZGGKlKpctKA3wNgEcl9ABZ52yA5neRL3jELAfw3ANeRfMP775aE5xWRpHZvBB67EnhoUvlRrRd8FalUOVFZZr2pLFOkTob77YxtwdDSBtz2ePzqHpWC5kI9yzJFRqzs3YMNOw5gyAwlEsvmt2N115ysL0v8hPXbiROkK79Ahhu2AQr6OaLWCpKKlb17sH77fgx5vzEOmWH99v1Y2bsn4ysTX2n321HDtqaggC+p2LDjQKT9krG0++2oYVtTUMCXVAwFjAUF7ZeMpd1vRw3bmoICvqSiREbaLxmbu7Q8QDuxHQDLj8MDtnGqdzJo2Na7awALe17FZd0vYmHPq+jdNVC3cxWFBm0lFcvmt2P99v2++yWn/PrtxB18HX6tQVU6Repv00gqy5TUqEqnAB670lsascLEduBLbzb+egIs7HnVd/brjElteL37ugyuKD9UlikNsbprjgJ8E/Ft+RswyHr2xEFs2jWQm7vnIvW3aSTl8EUcNJwSGTg+CMNoSuRkm1+fRODQ2Y/hvuf35CZPrqU441HAF3FQUMvfR05/9pzB15PWikfOLM1VS+Ai9bdpJAV8EQcFpT7WfXANcNvjOHh2Cs4acfDsFHSf/iNsOvvJ0D/XaEXqb9NIyuGLOCi05e/cW/HZl6bkviVw17wZCvAR6Q5fxBVj6uu38M/w+63/PO7lsSkRpUyKSXf4Ii6oqK+/YPAwelqewIWt52HdB9ecszD38GOzLNwttVEdvogLUq6v9y3p1JdBLqgOX8R1KTY30yzX5qUcvogLUmxuFlTSmZeSTQmmgC/ighSbm2mWa/NSSkfEBSk2Nwst6ZREPvc3P8Dr/3ZsZHvhb0zGM3/8u6m9v+7wRVwxd2l5gPah4+XHmJ0sVbJZH5XBHgBe/7dj+Nzf/CC1c+gOX0QiiVuyqcqecJXBvtr+OBTwRSTc7o3npIK65i2NFKxV2ZMPSumISLDhCVsnDgCw0QVRalkFawxV9uSDAr6IBNu6anT1q2GnB8v7I1BlT3ULf2NypP1xJAr4JCeT3EJyn/d4kc8x55P8Ickfk/wJyYeTnFNEGiilCVvqX1/dM3/8u+cE97SrdJLm8LsBbDWzHpLd3vZXKo75FYDrzOwDki0AtpH8rpltT3huEam3iTMDWjJEm7B1702Xj8vhA6rs8ZNmcPeTNKWzBMA67/k6AF2VB1jZB95mi/dffhv4iMiolCZsqX99PiS9w7/EzA4DgJkdJnmx30EkSwD6AXwcwDfMbEfC84pII6Q4YStS//rN9wD9TwM2BLAEXH0XsHhN5HPKeFUDPslXAPgtdHl/rScxsyEAV5GcBOA7JK80M98WfSRXAFgBAB0dHbWeQkTqZe7S2JO0Ytl8D9D35Oi2DY1uK+gnkqg9Msm9AK717u6nAXjNzEKTciQfBPChmf1VtfdXe2SR5pLK5KqHJ5eDfCWWgAfTm4RUVGHtkZPm8DcBWO49Xw7gBZ+TT/Xu7EGyDcANAH6a8LwikjPDk6sGjg/CMDq5qnfXQLQ38gv2YfulZkkDfg+ARST3AVjkbYPkdJIvecdMA/B9krsB7ASwxcw2JzyviORMapOrWIq2X2qWaNDWzH4B4Hqf/YcA3OI93w1gXpLziEj+pTa56uq7xufwx+6XRDTTVkRSkdrkqsVrgM7Pj97Rs1Te1oBtYmqeJiKpSHVy1eI1CvB1oIAvIqmI2zZZGkcBX0RSE2lyVQZc78mvgC8iuZZWkFZPfg3aikiOpVbbD/XkBxTwRSTH0gzS6smvlI6I5FiaQXr6pDYM+Py5rHryZzGeoDt8EcmtNBdOufemy9HWMn62blY9+dNMVUWhgC8iuZVmkM5TT/6sxhOU0hGR3Eq7tj8vZaNZjSco4ItIruUlSKcpq/EEpXRERBosq/EE3eGLSKZcnP2aVRsKBXwRyYzLs1+zSFUppSMimdHs18bSHb6IZKYe1SoupohqpTt8EclMmhOrgOwmNDULBXwRyUza1SpKEYVTSkdEMpN2tYoapIVTwBeRTKVZrZK3Bml5o5SOiBRGnhqk5ZHu8EWkMLSubjgFfBEplCL23kmLUjoiIo5IFPBJTia5heQ+7/GikGNLJHeR3JzknCIiEk/SO/xuAFvNbDaArd52kC8AeCvh+UREJKakAX8JgHXe83UAuvwOIjkTwK0Ankh4PhERiSnpoO0lZnYYAMzsMMmLA477GoAvA/hItTckuQLACgDo6OhIeHkiIrVxoQdP1YBP8hUAl/q8dH8tJyC5GMARM+sneW21481sLYC1ANDZ2Wm1nENEJAlX2jRXDfhmdkPQayTfJTnNu7ufBuCIz2ELAdxO8hYA5wP4KMn1ZnZn7KsWEUlRWA+eIgX8pDn8TQCWe8+XA3ih8gAzu8/MZprZLAB3AHhVwV5E8sSVHjxJA34PgEUk9wFY5G2D5HSSLyW9OBGRRki7TXNeJQr4ZvYLM7vezGZ7j8e8/YfM7Baf418zs8VJzikikjZXevCotYKIOM+VHjwK+CIicKMHj3rpiIg4QgFfRMQRCvgiIo5QwBcRcYQCvoiIIxTwRUQcoYAvIuIIBXwREUco4IuIOEIBX0TEEQr4IiKOUMAXEXGEAr6IiCMU8EVEHKGALyLiCAV8ERFHKOCLiDhCK16JiMS0sncPNuw4gCEzlEgsm9+O1V1zsr6sQAr4IiIxrOzdg/Xb949sD5mNbOc16CulIyISw4YdByLtzwMFfBGRGIbMIu3PAwV8EZEYSmSk/XmQKOCTnExyC8l93uNFAcf9O8k9JN8g2ZfknCIiebBsfnuk/XmQ9A6/G8BWM5sNYKu3HeT3zOwqM+tMeE4Rkcyt7pqDOxd0jNzRl0jcuaAjtwO2AEBLkG8iuRfAtWZ2mOQ0AK+Z2eU+x/07gE4zey/K+3d2dlpfn34hEBGpFcn+oBvrpHf4l5jZYQDwHi8OOM4AfI9kP8kVYW9IcgXJPpJ9R48eTXh5IiIyrGodPslXAFzq89L9Ec6z0MwOkbwYwBaSPzWzf/I70MzWAlgLlO/wI5xDRERCVA34ZnZD0Gsk3yU5bUxK50jAexzyHo+Q/A6AawD4BnwREamPpCmdTQCWe8+XA3ih8gCSv0byI8PPAdwI4M2E5xURkYiSBvweAItI7gOwyNsGyekkX/KOuQTANpI/BvBDAC+a2T8mPK+IiESUqEqn3kgeBfAfMf/4FACRqoIKyPXPwPWfH9BnALj3Gfy6mU31eyHXAT8Jkn2u1/y7/hm4/vMD+gwAfQZjqbWCiIgjFPBFRBxR5IC/NusLyAHXPwPXf35AnwGgz2BEYXP4IiIyXpHv8EVEZAwFfBERRxQu4JO8meRekm+TDGvXXBgknyJ5hOSbY/bVtFZBUZBsJ/l9km+R/AnJL3j7nfgcSJ5P8ockf+z9/A97+534+cciWSK5i+Rmb9u5zyBIoQI+yRKAbwD4FIArACwjeUW2V9UQTwO4uWJflLUKiuAMgP9lZr8FYAGAP/f+7l35HH4F4Doz+20AVwG4meQCuPPzj/UFAG+N2XbxM/BVqICPclO2t83sZ2Z2CsCzAJZkfE1153UePVaxewmAdd7zdQC6GnpRDWZmh83sR97z/0T5f/gZcORzsLIPvM0W7z+DIz//MJIzAdwK4Ikxu536DMIULeDPADB2yfiD3j4X1bpWQeGQnAVgHoAdcOhz8FIZb6DctXaLmTn183u+BuDLAM6O2efaZxCoaAHfb/Vg1Z06hOSFAJ4D8EUzez/r62kkMxsys6sAzARwDckrs76mRiK5GMARM+vP+lryqmgB/yCAsSsIzwRwKKNrydq73hoFCFuroEhItqAc7J8xs+e93c59DmZ2HMBrKI/ruPTzLwRwu7ek6rMAriO5Hm59BqGKFvB3AphN8jKSrQDuQLlnv4uqrlVQJCQJ4EkAb5nZmjEvOfE5kJxKcpL3vA3ADQB+Ckd+fgAws/vMbKaZzUL5//1XzexOOPQZVFO4mbYkb0E5j1cC8JSZ/WXGl1R3JDcAuBblNrDvAngQQC+AjQA6AOwH8AdmVjmwWxgkPwng/wLYg9H87f9GOY9f+M+B5FyUByRLKN/IbTSzVSQ/Bgd+/kokrwXwF2a22NXPwE/hAr6IiPgrWkpHREQCKOCLiDhCAV9ExBEK+CIijlDAFxFxhAK+iIgjFPBFRBzx/wEHTtsPWejAhQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent_id = 0\n",
    "agent_id_2 = 2\n",
    "plt.scatter(normalized_traj[agent_id][:, 0], normalized_traj[agent_id][:, 1])\n",
    "plt.scatter(normalized_traj[agent_id_2][:, 0], normalized_traj[agent_id_2][:, 1])\n",
    "# plt.yticks(range(-3, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2586.48364258, 1077.5904541 ],\n",
       "       [2587.25561523, 1078.26306152],\n",
       "       [2587.25561523, 1078.26306152],\n",
       "       [2588.93725586, 1079.73950195],\n",
       "       [2589.70117188, 1080.4498291 ],\n",
       "       [2590.4621582 , 1081.20788574],\n",
       "       [2591.34008789, 1081.96801758],\n",
       "       [2592.1418457 , 1082.69934082],\n",
       "       [2592.84960938, 1083.35864258],\n",
       "       [2593.65380859, 1084.15905762],\n",
       "       [2594.42749023, 1084.83056641],\n",
       "       [2595.10717773, 1085.40441895],\n",
       "       [2595.76123047, 1085.99206543],\n",
       "       [2596.42382812, 1086.72558594],\n",
       "       [2597.33984375, 1087.4005127 ],\n",
       "       [2597.33984375, 1087.4005127 ],\n",
       "       [2598.78027344, 1088.90258789],\n",
       "       [2598.78027344, 1088.90258789],\n",
       "       [2600.17797852, 1090.35534668],\n",
       "       [2600.93920898, 1091.00366211],\n",
       "       [2601.71044922, 1091.71435547],\n",
       "       [2602.46362305, 1092.42016602],\n",
       "       [2603.35644531, 1093.2232666 ],\n",
       "       [2604.06982422, 1093.97290039],\n",
       "       [2604.74682617, 1094.57336426],\n",
       "       [2605.53735352, 1095.29528809],\n",
       "       [2606.3034668 , 1095.99194336],\n",
       "       [2607.08081055, 1096.7409668 ],\n",
       "       [2607.64355469, 1097.26708984],\n",
       "       [2608.57177734, 1098.17456055],\n",
       "       [2609.36865234, 1098.80786133],\n",
       "       [2609.6418457 , 1098.8371582 ],\n",
       "       [2610.55566406, 1099.68969727],\n",
       "       [2611.27124023, 1100.32897949],\n",
       "       [2612.04785156, 1100.99084473],\n",
       "       [2612.82543945, 1101.75390625],\n",
       "       [2613.5703125 , 1102.33886719],\n",
       "       [2614.44213867, 1103.18811035],\n",
       "       [2615.06567383, 1103.90722656],\n",
       "       [2615.75415039, 1104.36157227],\n",
       "       [2616.60522461, 1105.20898438],\n",
       "       [2617.45336914, 1105.89697266],\n",
       "       [2618.04418945, 1106.73059082],\n",
       "       [2618.93457031, 1107.1763916 ],\n",
       "       [2618.93457031, 1107.1763916 ],\n",
       "       [2620.52929688, 1108.85046387],\n",
       "       [2621.05859375, 1109.43432617],\n",
       "       [2621.05859375, 1109.43432617],\n",
       "       [2621.05859375, 1109.43432617]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_utils.normalized_to_map_coordinates(\n",
    "    normalized_traj, translation, rotation\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_traj(coords: np.ndarray, mode: str=\"train\"):\n",
    "    \"\"\"\n",
    "    Normalize coordinates\n",
    "    1) translation and rotation\n",
    "    2) relative distance\n",
    "    \n",
    "    Args:\n",
    "        coords (np.ndarray): (num_tracks x seq_len x 2) coordinates\n",
    "        mode (str): train/val/test\n",
    "    Returns:\n",
    "        normalized_coords (np.ndarray): (num_tracks x seq_len x 2) normalized coordinates\n",
    "        helpers (dict): a dictionary of helpers\n",
    "    \"\"\"\n",
    "    norm_traj_arr, translation, rotation = baseline_utils.get_normalized_traj(coords, None)\n",
    "#     norm_traj_arr, reference = baseline_utils.get_relative_distance(norm_traj_arr, mode)\n",
    "    \n",
    "    helpers = {\n",
    "        \"translation\": translation,\n",
    "        \"rotation\": rotation,\n",
    "#         \"reference\": reference\n",
    "    }\n",
    "    return norm_traj_arr, helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absolute_distance(inp: np.ndarray, out: np.ndarray, helpers: dict):\n",
    "    obs_len, pred_len = len(inp), len(out)\n",
    "    reference = helpers[\"reference\"].copy()\n",
    "    inp[:, 0, :2] = reference\n",
    "    for i in range(1, obs_len):\n",
    "        inp[:, i, :2] = inp[:, i, :2] + inp[:, i - 1, :2]\n",
    "\n",
    "        out[:, 0, :2] = out[:, 0, :2] + inp[:, -1, :2]\n",
    "    for i in range(1, pred_len):\n",
    "        out[:, i, :2] = out[:, i, :2] + out[:, i - 1, :2]\n",
    "    return inp, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_denormalized_traj(inp: np.ndarray, out: np.ndarray, helpers: dict, mode: str=\"train\"):\n",
    "    \"\"\"\n",
    "    Denormalize coordinates\n",
    "    1) get absolute distance\n",
    "    2) inverse translation and rotation\n",
    "    \n",
    "    Args:\n",
    "        inp (np.ndarray): (num_tracks x seq_len x 2) normalized input coords\n",
    "        out (np.ndarray): (num_tracks x seq_len x 2) normalized output coords\n",
    "        helpers (dict): a dictionary of helpers\n",
    "        mode (str): train/val/test\n",
    "    Returns:\n",
    "        coords (np.ndarray): (num_tracks x seq_len x 2) coordinates\n",
    "    \"\"\"\n",
    "    # Convert relative to absolute\n",
    "#     inp, out = get_absolute_distance(inp, out, helpers)\n",
    "\n",
    "    # Denormalize trajectory\n",
    "    translation = helpers[\"translation\"].copy()\n",
    "    rotation = helpers[\"rotation\"].copy()\n",
    "    if inp is not None:\n",
    "        inp[:, :, :2] = baseline_utils.normalized_to_map_coordinates(\n",
    "            inp[:, :, :2], translation, rotation)\n",
    "\n",
    "    if out is not None:\n",
    "        out[:, :, :2] = baseline_utils.normalized_to_map_coordinates(\n",
    "            out[:, :, :2], translation, rotation)\n",
    "    return inp, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_traj, helpers = get_normalized_traj(social_trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = get_denormalized_traj(normalized_traj[:, :19, :], normalized_traj[:, 19:, :], helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_position(inp, out=None):\n",
    "    \"\"\"calculate position difference\"\"\"\n",
    "    input_length = inp.shape[1]\n",
    "    p_in_0 = copy.deepcopy(inp[:, 0, :2])\n",
    "    \n",
    "    \n",
    "    if out is not None:\n",
    "        out = copy.deepcopy(out)\n",
    "        output_length = out.shape[1]\n",
    "        for i in range(output_length - 1, 0, -1):\n",
    "            out[:, i, :2] = out[:, i, :2] - out[:, i - 1, :2]\n",
    "        out[:, 0, :2] = out[:, 0, :2] - inp[:, -1, :2]\n",
    "        \n",
    "    for i in range(input_length - 1, 0, -1):\n",
    "        inp[:, i, :2] = inp[:, i, :2] - inp[:, i - 1, :2]\n",
    "    inp[:, 0, :] = 0\n",
    "    \n",
    "    if out is not None:\n",
    "        return inp, out, p_in_0\n",
    "    \n",
    "    return inp, p_in_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absolute_position(inp, out, p_in_0, return_pred_only=False):\n",
    "    \"\"\"position inverse difference\"\"\"\n",
    "    inp[:, 0, :2] = p_in_0\n",
    "    for i in range(1, inp.shape[1]):\n",
    "        inp[:, i, :2] = inp[:, i, :2] + inp[:, i - 1, :2]\n",
    "\n",
    "    out[:, 0, :2] = out[:, 0, :2] + inp[:, -1, :2]\n",
    "    for i in range(1, out.shape[1]):\n",
    "        out[:, i, :2] = out[:, i, :2] + out[:, i - 1, :2]\n",
    "    \n",
    "    if return_pred_only:\n",
    "        return out\n",
    "    \n",
    "    return inp, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f503b0c8d90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sample = train[8]\n",
    "agent_id = 2\n",
    "plt.scatter(train_sample['lane'][:, 0], train_sample['lane'][:, 1])\n",
    "plt.scatter(train_sample['p_in'][agent_id][:, 0], train_sample['p_in'][agent_id][:, 1])\n",
    "plt.scatter(train_sample['p_out'][agent_id][:, 0], train_sample['p_out'][agent_id][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5001f1ffd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train_sample['lane_norm'][:, 0], train_sample['lane_norm'][:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(torch.nn.Module):\n",
    "    \"\"\"RMSE Loss\"\"\"\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = torch.sqrt(criterion(yhat, y))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training config\n",
    "ROLLOUT_LEN = 30\n",
    "\n",
    "# model config\n",
    "INPUT_SIZE = 4\n",
    "EMBEDDING_SIZE = 16\n",
    "HIDDEN_SIZE = 256\n",
    "OUTPUT_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.linear = nn.Linear(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTMCell(embedding_size, hidden_size)\n",
    "\n",
    "    def init_hidden(self, batch_size, hidden_size):\n",
    "        # Initialize encoder hidden state\n",
    "        h_0 = torch.zeros(batch_size, hidden_size).to(device)\n",
    "        c_0 = torch.zeros(batch_size, hidden_size).to(device)\n",
    "        nn.init.xavier_normal_(h_0)\n",
    "        nn.init.xavier_normal_(c_0)\n",
    "        return (h_0, c_0)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        init_hidden = self.init_hidden(X.shape[0], self.hidden_size)\n",
    "        \n",
    "        embedded = F.relu(self.linear(X))\n",
    "        hidden_state = self.lstm(embedded, init_hidden)\n",
    "        return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, embedding_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE, output_size=OUTPUT_SIZE):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.linear1 = nn.Linear(output_size, embedding_size)\n",
    "        self.lstm1 = nn.LSTMCell(embedding_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "#         self.linear3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X, encoder_hidden):        \n",
    "        out = F.relu(self.linear1(X))\n",
    "        hidden = self.lstm1(out, encoder_hidden)\n",
    "        out = self.linear2(hidden[0])\n",
    "#         out = self.linear3(out)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size: int,\n",
    "                 embedding_size: int=EMBEDDING_SIZE,\n",
    "                 hidden_size: int=HIDDEN_SIZE,\n",
    "                 pred_len: int=30,\n",
    "                 use_teacher_forcing: bool=False\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): input size\n",
    "            pred_len (int): prediction length\n",
    "            use_teacher_forcing (bool): whether to use teacher forcing technique\n",
    "        \"\"\"\n",
    "        super(TrajectoryModel, self).__init__()\n",
    "        self.pred_len = pred_len\n",
    "        self.use_teacher_forcing = use_teacher_forcing\n",
    "        \n",
    "        self.encoder = EncoderLSTM(input_size, embedding_size, hidden_size)\n",
    "        self.decoder = DecoderLSTM(embedding_size, hidden_size)\n",
    "    \n",
    "    def forward(self, inp: np.ndarray, out: np.ndarray=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inp (np.ndarray): (num_tracks x obs_len x input_size) input trajectory\n",
    "            out (np.ndarray): (optional) (num_tracks x pred_len x input_size) output trajectory\n",
    "        Returns:\n",
    "            decoder_outputs (np.ndarray): (num_tracks x obs_len x input_size) decoder outputs\n",
    "        \"\"\"\n",
    "        input_length = inp.shape[1]\n",
    "        for i in range(input_length):\n",
    "            encoder_input = inp[:, i, :]\n",
    "            encoder_hidden = self.encoder(encoder_input)\n",
    "    \n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "        decoder_outputs = torch.zeros((len(inp), self.pred_len, 2))\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "        for i in range(self.pred_len):\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            # record decoder_output\n",
    "            decoder_outputs[:, i, :] = decoder_output\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            if self.use_teacher_forcing and out is not None:\n",
    "                decoder_input = out[:, i, :2]\n",
    "            else:\n",
    "                decoder_input = decoder_output\n",
    "                \n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_validation(val_loader, model):\n",
    "    loss_fn = RMSELoss()\n",
    "    \n",
    "    losses = []\n",
    "    for i_batch, batch_data in enumerate(val_loader):\n",
    "        inp, out = batch_data\n",
    "#         inp = inp.to(device)\n",
    "#         out = out.to(device)\n",
    "        \n",
    "        # eval mode\n",
    "        model.eval()\n",
    "\n",
    "        # Get relative position\n",
    "#         initial_p_in = inp[:, 0, :2].detach().clone()\n",
    "#         inp[:, :, :2] = inp[:, :, :2] - initial_p_in[:, None]\n",
    "#         out[:, :, :2] = out[:, :, :2] - initial_p_in[:, None]\n",
    "        \n",
    "        normalized_traj, helpers = get_normalized_traj(np.concatenate([inp[:, :, :2], out], axis=1))\n",
    "        norm_inp = np.concatenate([normalized_traj[:, :19, :], inp[:, :, 2:]], axis=2)\n",
    "        norm_inp = torch.FloatTensor(norm_inp[:, :19, :]).to(device)\n",
    "        norm_out = torch.FloatTensor(normalized_traj[:, 19:, :]).to(device)\n",
    "        \n",
    "        # model training\n",
    "        decoder_outputs = model(norm_inp)\n",
    "\n",
    "        # calculate loss \n",
    "        loss = loss_fn(decoder_outputs, norm_out.cpu())\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    loss = np.mean(losses)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "tracjectory_model = TrajectoryModel(4, use_teacher_forcing=False)\n",
    "tracjectory_model.to(device)\n",
    "\n",
    "loss_fn = RMSELoss()\n",
    "tracjectory_optimizer = torch.optim.Adam(tracjectory_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3057/3057 [03:59<00:00, 12.77it/s, epoch=1, loss=2.855910301208496, avg.=4.088736684251385]  \n",
      "  0%|          | 2/3057 [00:00<03:29, 14.61it/s, epoch=2, loss=3.6904094219207764, avg.=3.364051421483358] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training loss: 2.8559, Val loss: 3.2448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3057/3057 [03:30<00:00, 14.52it/s, epoch=2, loss=3.2880804538726807, avg.=3.3250531057614223]\n",
      "  0%|          | 2/3057 [00:00<03:32, 14.40it/s, epoch=3, loss=3.533979654312134, avg.=3.7795382738113403]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Training loss: 3.2881, Val loss: 3.2117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3057/3057 [03:40<00:00, 13.87it/s, epoch=3, loss=3.069485902786255, avg.=3.2892954406451276] \n",
      "  0%|          | 2/3057 [00:00<03:50, 13.28it/s, epoch=4, loss=3.4537439346313477, avg.=3.3634018898010254]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Training loss: 3.0695, Val loss: 3.2924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3057/3057 [03:43<00:00, 13.66it/s, epoch=4, loss=2.9438858032226562, avg.=3.27656341277582]  \n",
      "  0%|          | 2/3057 [00:00<03:46, 13.48it/s, epoch=5, loss=2.889224052429199, avg.=3.2305071353912354]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Training loss: 2.9439, Val loss: 3.2043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3057/3057 [03:46<00:00, 13.49it/s, epoch=5, loss=2.8460779190063477, avg.=3.2600935203482364]\n",
      "  0%|          | 2/3057 [00:00<03:47, 13.46it/s, epoch=6, loss=2.7624902725219727, avg.=3.0406668186187744]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Training loss: 2.8461, Val loss: 3.1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1748/3057 [02:07<01:35, 13.74it/s, epoch=6, loss=4.1058831214904785, avg.=3.248956238514226] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-589d3aaf270c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtracjectory_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mtracjectory_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# print loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "prev_loss, non_decreasing_loss_cnt = -float(\"inf\"), 0\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    train_iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for i_batch, batch_data in enumerate(train_iterator):\n",
    "        inp, out = batch_data\n",
    "#         inp = inp.to(device)\n",
    "#         out = out.to(device)\n",
    "        \n",
    "        # Set to train mode\n",
    "        tracjectory_model.train()\n",
    "\n",
    "        # Get relative position  \n",
    "#         initial_p_in = inp[:, 0, :2].detach().clone()\n",
    "#         inp[:, :, :2] = inp[:, :, :2] - initial_p_in[:, None]\n",
    "#         out[:, :, :2] = out[:, :, :2] - initial_p_in[:, None]\n",
    "        normalized_traj, helpers = get_normalized_traj(np.concatenate([inp[:, :, :2], out], axis=1))\n",
    "        norm_inp = np.concatenate([normalized_traj[:, :19, :], inp[:, :, 2:]], axis=2)\n",
    "        norm_inp = torch.FloatTensor(norm_inp[:, :19, :]).to(device)\n",
    "        norm_out = torch.FloatTensor(normalized_traj[:, 19:, :]).to(device)\n",
    "        \n",
    "        # model training\n",
    "        decoder_outputs = tracjectory_model(norm_inp)\n",
    "\n",
    "        # Get average loss for pred_len\n",
    "        loss = loss_fn(decoder_outputs, norm_out.cpu())\n",
    "#         pred_out = decoder_outputs[:, :, :2].detach().cpu().numpy() + initial_p_in[:, None].detach().cpu().numpy()\n",
    "\n",
    "        # Backpropagate\n",
    "        tracjectory_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        tracjectory_optimizer.step()\n",
    "            \n",
    "        # print loss\n",
    "        total += loss.item()\n",
    "        count += 1\n",
    "        train_iterator.set_postfix_str(\"epoch={}, loss={}, avg.={}\".format(epoch+1, loss.item(), total/count))\n",
    "            \n",
    "    # validate after each epoch\n",
    "    with torch.no_grad():\n",
    "        val_loss = check_validation(val_loader, tracjectory_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size=30*2):\n",
    "        super(ConvMLP, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(19, 64, kernel_size=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(64, 256, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.conv(x)\n",
    "        x = x.view(len(x), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_validation(val_loader, model):\n",
    "    loss_fn = RMSELoss()\n",
    "    \n",
    "    iterator = tqdm(val_loader, total=int(len(val_loader)))\n",
    "    total = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for i_batch, batch_data in enumerate(iterator):\n",
    "            inp, out = batch_data\n",
    "    #         inp = inp.to(device)\n",
    "    #         out = out.to(device)\n",
    "\n",
    "            # eval mode\n",
    "            model.eval()\n",
    "\n",
    "            # Get relative position\n",
    "    #         initial_p_in = inp[:, 0, :2].detach().clone()\n",
    "    #         inp[:, :, :2] = inp[:, :, :2] - initial_p_in[:, None]\n",
    "    #         out[:, :, :2] = out[:, :, :2] - initial_p_in[:, None]\n",
    "\n",
    "            normalized_traj, helpers = get_normalized_traj(np.concatenate([inp[:, :, :2], out], axis=1))\n",
    "            norm_inp = np.concatenate([normalized_traj[:, :19, :], inp[:, :, 2:]], axis=2)\n",
    "            norm_inp = torch.FloatTensor(norm_inp).to(device)\n",
    "            norm_out = torch.FloatTensor(normalized_traj[:, 19:, :]).to(device)\n",
    "\n",
    "            # model training\n",
    "            pred_norm_out = model(norm_inp)\n",
    "\n",
    "            # calculate loss \n",
    "            loss = loss_fn(pred_norm_out, norm_out.flatten(start_dim=1))\n",
    "\n",
    "            # print loss\n",
    "            total += loss.item()\n",
    "            count += 1\n",
    "            iterator.set_postfix_str(\"Validation: loss={}, avg.={}\".format(loss.item(), total/count))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "model = ConvMLP(4)\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = RMSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48911/48911 [05:27<00:00, 149.39it/s, loss=2.80572247505188, avg.=2.5856770695508584]   \n",
      "100%|██████████| 2575/2575 [00:10<00:00, 241.03it/s, Validation: loss=2.1204466819763184, avg.=2.3117589671171985] \n",
      "100%|██████████| 48911/48911 [05:27<00:00, 149.53it/s, loss=2.724747896194458, avg.=2.3461704347442973]  \n",
      "100%|██████████| 2575/2575 [00:10<00:00, 240.21it/s, Validation: loss=1.2013643980026245, avg.=2.2796839253069128] \n",
      "100%|██████████| 48911/48911 [05:40<00:00, 143.63it/s, loss=3.157212018966675, avg.=2.2981753265821623]  \n",
      "100%|██████████| 2575/2575 [00:11<00:00, 232.62it/s, Validation: loss=1.8900516033172607, avg.=2.3992119953007376]\n",
      " 18%|█▊        | 8789/48911 [01:01<04:18, 154.98it/s, loss=1.6925755739212036, avg.=2.2941421818733216] "
     ]
    }
   ],
   "source": [
    "# training\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "prev_loss, non_decreasing_loss_cnt = -float(\"inf\"), 0\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    train_iterator = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for i_batch, batch_data in enumerate(train_iterator):\n",
    "        inp, out = batch_data\n",
    "#         inp = inp.to(device)\n",
    "#         out = out.to(device)\n",
    "\n",
    "        # Set to train mode\n",
    "        model.train()\n",
    "\n",
    "        # Get relative position  \n",
    "        normalized_traj, helpers = get_normalized_traj(np.concatenate([inp[:, :, :2], out], axis=1))\n",
    "        norm_inp = np.concatenate([normalized_traj[:, :19, :], inp[:, :, 2:]], axis=2)\n",
    "        norm_inp = torch.FloatTensor(norm_inp).to(device)\n",
    "        norm_out = torch.FloatTensor(normalized_traj[:, 19:, :]).to(device)\n",
    "#         initial_p_in = inp[:, 0, :2].detach().clone()\n",
    "#         inp[:, :, :2] = inp[:, :, :2] - initial_p_in[:, None]\n",
    "#         out[:, :, :2] = out[:, :, :2] - initial_p_in[:, None]\n",
    "        \n",
    "        # model training\n",
    "        pred_norm_out = model(norm_inp)\n",
    "\n",
    "        # Get average loss for pred_len\n",
    "        loss = loss_fn(pred_norm_out, norm_out.flatten(start_dim=1))\n",
    "#         pred_out = decoder_outputs[:, :, :2].detach().cpu().numpy() + initial_p_in[:, None].detach().cpu().numpy()\n",
    "\n",
    "        # Backpropagate\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss\n",
    "        total += loss.item()\n",
    "        count += 1\n",
    "        train_iterator.set_postfix_str(\"loss={}, avg.={}\".format(loss.item(), total/count))\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        check_validation(val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "pred_p_out = np.array([])\n",
    "all_zeros_ix = []\n",
    "real_inp = None\n",
    "with torch.no_grad():\n",
    "    for i_batch, batch_data in enumerate(test_loader):\n",
    "        inp, out = batch_data\n",
    "        inp = inp.to(device)\n",
    "                    \n",
    "        # Set to eval mode\n",
    "        tracjectory_model.eval()\n",
    "\n",
    "        # Encoder\n",
    "        batch_size = inp.shape[0]\n",
    "        input_length = inp.shape[1]\n",
    "        input_shape = inp.shape[2]\n",
    "\n",
    "        # Get relative position\n",
    "        initial_p_in = inp[:, 0, :2].detach().clone()\n",
    "        real_inp = inp.detach().clone()\n",
    "        inp[:, :, :2] = inp[:, :, :2] - initial_p_in[:, None]\n",
    "#         inp, p_in_0 = get_relative_position(inp)\n",
    "        \n",
    "        # Encode observed trajectory\n",
    "        decoder_outputs = tracjectory_model(inp)\n",
    "        pred_out = decoder_outputs[:, :, :2].detach().cpu() + initial_p_in[:, None].detach().cpu()\n",
    "            \n",
    "        # predicted_p_out\n",
    "#         out = get_absolute_position(inp, decoder_outputs.to(device), p_in_0, return_pred_only=True)\n",
    "#         pred_p_out.append(pred_out)\n",
    "        pred_p_out = np.append(pred_p_out, pred_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "pred_p_out = np.array([])\n",
    "all_zeros_ix = []\n",
    "real_inp = None\n",
    "with torch.no_grad():\n",
    "    for i_batch, batch_data in enumerate(test_loader):\n",
    "        inp, out = batch_data\n",
    "#         inp = inp.to(device)\n",
    "                    \n",
    "        # Set to eval mode\n",
    "        model.eval()\n",
    "\n",
    "        # Encoder\n",
    "        batch_size = inp.shape[0]\n",
    "        input_length = inp.shape[1]\n",
    "        input_shape = inp.shape[2]\n",
    "\n",
    "        # Get relative position\n",
    "#         initial_p_in = inp[:, 0, :2].detach().clone()\n",
    "#         real_inp = inp.detach().clone()\n",
    "#         inp[:, :, :2] = inp[:, :, :2] - initial_p_in[:, None]\n",
    "        normalized_traj, helpers = get_normalized_traj(inp[:, :, :2])\n",
    "        norm_inp = np.concatenate([normalized_traj[:, :19, :], inp[:, :, 2:]], axis=2)\n",
    "        norm_inp = torch.FloatTensor(norm_inp[:, :19, :]).to(device)\n",
    "            \n",
    "        # Encode observed trajectory\n",
    "        pred_norm_out = model(norm_inp)\n",
    "        pred_out = pred_norm_out.view(batch_size, 30, -1)\n",
    "#         pred_out = decoder_outputs[:, :, :2].detach().cpu() + initial_p_in[:, None].detach().cpu()\n",
    "        _, pred_out = get_denormalized_traj(norm_inp[:, :, :2].detach().cpu().numpy(), pred_out.detach().cpu().numpy(), helpers)\n",
    "            \n",
    "        # predicted_p_out\n",
    "#         out = get_absolute_position(inp, decoder_outputs.to(device), p_in_0, return_pred_only=True)\n",
    "#         pred_p_out.append(pred_out)\n",
    "        pred_p_out = np.append(pred_p_out, pred_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./convMLP_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1714.8306,  337.3518],\n",
       "         [1715.6418,  338.0697],\n",
       "         [1716.5616,  338.6626],\n",
       "         ...,\n",
       "         [1738.2598,  359.0963],\n",
       "         [1739.2419,  359.9876],\n",
       "         [1740.4204,  361.1639]],\n",
       "\n",
       "        [[ 724.1318, 1229.1752],\n",
       "         [ 724.7794, 1229.1013],\n",
       "         [ 724.3248, 1228.5420],\n",
       "         ...,\n",
       "         [ 720.2282, 1221.0304],\n",
       "         [ 720.0973, 1221.0149],\n",
       "         [ 720.0373, 1220.9846]],\n",
       "\n",
       "        [[ 573.3198, 1243.8040],\n",
       "         [ 573.6983, 1243.6085],\n",
       "         [ 574.5244, 1243.7225],\n",
       "         ...,\n",
       "         [ 579.4186, 1235.3717],\n",
       "         [ 579.7032, 1235.5059],\n",
       "         [ 580.0345, 1235.4381]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1756.1843,  443.2197],\n",
       "         [1755.5344,  444.2666],\n",
       "         [1755.1195,  444.5257],\n",
       "         ...,\n",
       "         [1745.5610,  449.7808],\n",
       "         [1745.5002,  449.9527],\n",
       "         [1745.4482,  450.0604]],\n",
       "\n",
       "        [[ 574.2961, 1289.6335],\n",
       "         [ 574.3181, 1289.3290],\n",
       "         [ 574.4839, 1289.3782],\n",
       "         ...,\n",
       "         [ 570.3430, 1282.6562],\n",
       "         [ 570.1480, 1282.4583],\n",
       "         [ 569.9148, 1282.4592]],\n",
       "\n",
       "        [[ 584.5436, 1164.8856],\n",
       "         [ 584.0893, 1163.5364],\n",
       "         [ 584.8909, 1162.6512],\n",
       "         ...,\n",
       "         [ 586.5665, 1136.2461],\n",
       "         [ 586.5546, 1135.4469],\n",
       "         [ 586.5749, 1134.7312]]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_p_out = torch.FloatTensor(len(val_loader), 30, 2)#.to(device)\n",
    "torch.cat(pred_p_out, out=predicted_p_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_out_list = predicted_p_out.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_any() missing 1 required keyword-only argument: 'where'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    392\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mline_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mmax_colwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_colwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             \u001b[0mshow_dimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_dimensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m         )\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, min_rows, max_cols, show_dimensions, decimal, line_width, max_colwidth, encoding)\u001b[0m\n\u001b[1;32m    879\u001b[0m                 \u001b[0mshow_dimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_dimensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m                 \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m                 \u001b[0mline_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m             )\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, frame, columns, col_space, header, index, na_rep, formatters, justify, float_format, sparsify, index_names, line_width, max_rows, min_rows, max_cols, show_dimensions, decimal, table_id, render_links, bold_rows, escape)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chk_truncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_adjustment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_chk_truncate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                 \u001b[0mrow_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_rows_adj\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr_row_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m             \u001b[0mndims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(self, inplace)\u001b[0m\n\u001b[1;32m   5230\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5232\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5234\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5212\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5201\u001b[0m         \"\"\"\n\u001b[1;32m   5202\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5203\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5211\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SingleBlockManager\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mnew_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m             \u001b[0;31m# TODO: can we avoid this?  it isn't cheap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gaps in blk ref_locs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _any() missing 1 required keyword-only argument: 'where'"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_any() missing 1 required keyword-only argument: 'where'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m                 \u001b[0mtable_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m                 \u001b[0mrender_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m             )\n\u001b[1;32m    798\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, frame, columns, col_space, header, index, na_rep, formatters, justify, float_format, sparsify, index_names, line_width, max_rows, min_rows, max_cols, show_dimensions, decimal, table_id, render_links, bold_rows, escape)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chk_truncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_adjustment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_chk_truncate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                 \u001b[0mrow_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_rows_adj\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr_row_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m             \u001b[0mndims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(self, inplace)\u001b[0m\n\u001b[1;32m   5230\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5232\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5234\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5212\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5201\u001b[0m         \"\"\"\n\u001b[1;32m   5202\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5203\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5211\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SingleBlockManager\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mnew_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m             \u001b[0;31m# TODO: can we avoid this?  it isn't cheap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gaps in blk ref_locs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _any() missing 1 required keyword-only argument: 'where'"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(pred_out_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v51</th>\n",
       "      <th>v52</th>\n",
       "      <th>v53</th>\n",
       "      <th>v54</th>\n",
       "      <th>v55</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58</th>\n",
       "      <th>v59</th>\n",
       "      <th>v60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1714.842163</td>\n",
       "      <td>337.056671</td>\n",
       "      <td>1715.699097</td>\n",
       "      <td>338.048157</td>\n",
       "      <td>1716.643677</td>\n",
       "      <td>338.915985</td>\n",
       "      <td>1717.606934</td>\n",
       "      <td>339.867767</td>\n",
       "      <td>1718.577759</td>\n",
       "      <td>340.778015</td>\n",
       "      <td>...</td>\n",
       "      <td>1738.091431</td>\n",
       "      <td>359.684631</td>\n",
       "      <td>1739.020752</td>\n",
       "      <td>360.514374</td>\n",
       "      <td>1739.964355</td>\n",
       "      <td>361.383942</td>\n",
       "      <td>1740.915405</td>\n",
       "      <td>362.252716</td>\n",
       "      <td>1741.877075</td>\n",
       "      <td>363.102844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725.461243</td>\n",
       "      <td>1229.644653</td>\n",
       "      <td>725.351440</td>\n",
       "      <td>1229.402222</td>\n",
       "      <td>725.264954</td>\n",
       "      <td>1229.104858</td>\n",
       "      <td>725.148499</td>\n",
       "      <td>1228.881226</td>\n",
       "      <td>724.991699</td>\n",
       "      <td>1228.598511</td>\n",
       "      <td>...</td>\n",
       "      <td>721.353149</td>\n",
       "      <td>1224.213135</td>\n",
       "      <td>721.075500</td>\n",
       "      <td>1223.997559</td>\n",
       "      <td>720.779297</td>\n",
       "      <td>1223.956665</td>\n",
       "      <td>720.498901</td>\n",
       "      <td>1223.598145</td>\n",
       "      <td>720.229675</td>\n",
       "      <td>1223.427124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>574.294495</td>\n",
       "      <td>1244.495972</td>\n",
       "      <td>574.499207</td>\n",
       "      <td>1244.314697</td>\n",
       "      <td>574.723267</td>\n",
       "      <td>1244.158203</td>\n",
       "      <td>574.912048</td>\n",
       "      <td>1243.989624</td>\n",
       "      <td>575.132629</td>\n",
       "      <td>1243.784790</td>\n",
       "      <td>...</td>\n",
       "      <td>579.535645</td>\n",
       "      <td>1238.270874</td>\n",
       "      <td>579.729431</td>\n",
       "      <td>1237.927734</td>\n",
       "      <td>579.898865</td>\n",
       "      <td>1237.576904</td>\n",
       "      <td>580.119995</td>\n",
       "      <td>1237.219849</td>\n",
       "      <td>580.334167</td>\n",
       "      <td>1236.833130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1691.317017</td>\n",
       "      <td>315.481720</td>\n",
       "      <td>1691.931030</td>\n",
       "      <td>316.177155</td>\n",
       "      <td>1692.618164</td>\n",
       "      <td>316.777557</td>\n",
       "      <td>1693.320312</td>\n",
       "      <td>317.445312</td>\n",
       "      <td>1694.024536</td>\n",
       "      <td>318.081268</td>\n",
       "      <td>...</td>\n",
       "      <td>1708.731079</td>\n",
       "      <td>331.712708</td>\n",
       "      <td>1709.437012</td>\n",
       "      <td>332.327057</td>\n",
       "      <td>1710.143433</td>\n",
       "      <td>332.959167</td>\n",
       "      <td>1710.896484</td>\n",
       "      <td>333.608765</td>\n",
       "      <td>1711.608154</td>\n",
       "      <td>334.212708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2122.486816</td>\n",
       "      <td>677.054199</td>\n",
       "      <td>2121.262207</td>\n",
       "      <td>675.803833</td>\n",
       "      <td>2119.931641</td>\n",
       "      <td>674.727417</td>\n",
       "      <td>2118.570068</td>\n",
       "      <td>673.543152</td>\n",
       "      <td>2117.205322</td>\n",
       "      <td>672.424927</td>\n",
       "      <td>...</td>\n",
       "      <td>2089.961426</td>\n",
       "      <td>649.322632</td>\n",
       "      <td>2088.695312</td>\n",
       "      <td>648.320862</td>\n",
       "      <td>2087.381592</td>\n",
       "      <td>647.251953</td>\n",
       "      <td>2086.074951</td>\n",
       "      <td>646.237854</td>\n",
       "      <td>2084.768311</td>\n",
       "      <td>645.246948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            v1           v2           v3           v4           v5  \\\n",
       "0  1714.842163   337.056671  1715.699097   338.048157  1716.643677   \n",
       "1   725.461243  1229.644653   725.351440  1229.402222   725.264954   \n",
       "2   574.294495  1244.495972   574.499207  1244.314697   574.723267   \n",
       "3  1691.317017   315.481720  1691.931030   316.177155  1692.618164   \n",
       "4  2122.486816   677.054199  2121.262207   675.803833  2119.931641   \n",
       "\n",
       "            v6           v7           v8           v9          v10  ...  \\\n",
       "0   338.915985  1717.606934   339.867767  1718.577759   340.778015  ...   \n",
       "1  1229.104858   725.148499  1228.881226   724.991699  1228.598511  ...   \n",
       "2  1244.158203   574.912048  1243.989624   575.132629  1243.784790  ...   \n",
       "3   316.777557  1693.320312   317.445312  1694.024536   318.081268  ...   \n",
       "4   674.727417  2118.570068   673.543152  2117.205322   672.424927  ...   \n",
       "\n",
       "           v51          v52          v53          v54          v55  \\\n",
       "0  1738.091431   359.684631  1739.020752   360.514374  1739.964355   \n",
       "1   721.353149  1224.213135   721.075500  1223.997559   720.779297   \n",
       "2   579.535645  1238.270874   579.729431  1237.927734   579.898865   \n",
       "3  1708.731079   331.712708  1709.437012   332.327057  1710.143433   \n",
       "4  2089.961426   649.322632  2088.695312   648.320862  2087.381592   \n",
       "\n",
       "           v56          v57          v58          v59          v60  \n",
       "0   361.383942  1740.915405   362.252716  1741.877075   363.102844  \n",
       "1  1223.956665   720.498901  1223.598145   720.229675  1223.427124  \n",
       "2  1237.576904   580.119995  1237.219849   580.334167  1236.833130  \n",
       "3   332.959167  1710.896484   333.608765  1711.608154   334.212708  \n",
       "4   647.251953  2086.074951   646.237854  2084.768311   645.246948  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make final submission dataframe\n",
    "# df = pd.DataFrame(predicted_p_out.view(3200, -1).cpu().numpy(), columns=[f\"v{i}\" for i in range(1, 61)])\n",
    "df = pd.DataFrame(pred_p_out.reshape(3200,  60), columns=[f\"v{i}\" for i in range(1, 61)])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v51</th>\n",
       "      <th>v52</th>\n",
       "      <th>v53</th>\n",
       "      <th>v54</th>\n",
       "      <th>v55</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58</th>\n",
       "      <th>v59</th>\n",
       "      <th>v60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>1714.842163</td>\n",
       "      <td>337.056671</td>\n",
       "      <td>1715.699097</td>\n",
       "      <td>338.048157</td>\n",
       "      <td>1716.643677</td>\n",
       "      <td>338.915985</td>\n",
       "      <td>1717.606934</td>\n",
       "      <td>339.867767</td>\n",
       "      <td>1718.577759</td>\n",
       "      <td>...</td>\n",
       "      <td>1738.091431</td>\n",
       "      <td>359.684631</td>\n",
       "      <td>1739.020752</td>\n",
       "      <td>360.514374</td>\n",
       "      <td>1739.964355</td>\n",
       "      <td>361.383942</td>\n",
       "      <td>1740.915405</td>\n",
       "      <td>362.252716</td>\n",
       "      <td>1741.877075</td>\n",
       "      <td>363.102844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10015</td>\n",
       "      <td>725.461243</td>\n",
       "      <td>1229.644653</td>\n",
       "      <td>725.351440</td>\n",
       "      <td>1229.402222</td>\n",
       "      <td>725.264954</td>\n",
       "      <td>1229.104858</td>\n",
       "      <td>725.148499</td>\n",
       "      <td>1228.881226</td>\n",
       "      <td>724.991699</td>\n",
       "      <td>...</td>\n",
       "      <td>721.353149</td>\n",
       "      <td>1224.213135</td>\n",
       "      <td>721.075500</td>\n",
       "      <td>1223.997559</td>\n",
       "      <td>720.779297</td>\n",
       "      <td>1223.956665</td>\n",
       "      <td>720.498901</td>\n",
       "      <td>1223.598145</td>\n",
       "      <td>720.229675</td>\n",
       "      <td>1223.427124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10019</td>\n",
       "      <td>574.294495</td>\n",
       "      <td>1244.495972</td>\n",
       "      <td>574.499207</td>\n",
       "      <td>1244.314697</td>\n",
       "      <td>574.723267</td>\n",
       "      <td>1244.158203</td>\n",
       "      <td>574.912048</td>\n",
       "      <td>1243.989624</td>\n",
       "      <td>575.132629</td>\n",
       "      <td>...</td>\n",
       "      <td>579.535645</td>\n",
       "      <td>1238.270874</td>\n",
       "      <td>579.729431</td>\n",
       "      <td>1237.927734</td>\n",
       "      <td>579.898865</td>\n",
       "      <td>1237.576904</td>\n",
       "      <td>580.119995</td>\n",
       "      <td>1237.219849</td>\n",
       "      <td>580.334167</td>\n",
       "      <td>1236.833130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10028</td>\n",
       "      <td>1691.317017</td>\n",
       "      <td>315.481720</td>\n",
       "      <td>1691.931030</td>\n",
       "      <td>316.177155</td>\n",
       "      <td>1692.618164</td>\n",
       "      <td>316.777557</td>\n",
       "      <td>1693.320312</td>\n",
       "      <td>317.445312</td>\n",
       "      <td>1694.024536</td>\n",
       "      <td>...</td>\n",
       "      <td>1708.731079</td>\n",
       "      <td>331.712708</td>\n",
       "      <td>1709.437012</td>\n",
       "      <td>332.327057</td>\n",
       "      <td>1710.143433</td>\n",
       "      <td>332.959167</td>\n",
       "      <td>1710.896484</td>\n",
       "      <td>333.608765</td>\n",
       "      <td>1711.608154</td>\n",
       "      <td>334.212708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003</td>\n",
       "      <td>2122.486816</td>\n",
       "      <td>677.054199</td>\n",
       "      <td>2121.262207</td>\n",
       "      <td>675.803833</td>\n",
       "      <td>2119.931641</td>\n",
       "      <td>674.727417</td>\n",
       "      <td>2118.570068</td>\n",
       "      <td>673.543152</td>\n",
       "      <td>2117.205322</td>\n",
       "      <td>...</td>\n",
       "      <td>2089.961426</td>\n",
       "      <td>649.322632</td>\n",
       "      <td>2088.695312</td>\n",
       "      <td>648.320862</td>\n",
       "      <td>2087.381592</td>\n",
       "      <td>647.251953</td>\n",
       "      <td>2086.074951</td>\n",
       "      <td>646.237854</td>\n",
       "      <td>2084.768311</td>\n",
       "      <td>645.246948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>9897</td>\n",
       "      <td>256.462372</td>\n",
       "      <td>805.223816</td>\n",
       "      <td>256.681396</td>\n",
       "      <td>804.911438</td>\n",
       "      <td>256.906006</td>\n",
       "      <td>804.566833</td>\n",
       "      <td>257.122406</td>\n",
       "      <td>804.231201</td>\n",
       "      <td>257.328644</td>\n",
       "      <td>...</td>\n",
       "      <td>260.885498</td>\n",
       "      <td>794.862732</td>\n",
       "      <td>261.016510</td>\n",
       "      <td>794.362244</td>\n",
       "      <td>261.129303</td>\n",
       "      <td>793.891174</td>\n",
       "      <td>261.299316</td>\n",
       "      <td>793.375854</td>\n",
       "      <td>261.450745</td>\n",
       "      <td>792.865601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>99</td>\n",
       "      <td>587.784851</td>\n",
       "      <td>1154.007202</td>\n",
       "      <td>587.875916</td>\n",
       "      <td>1153.310669</td>\n",
       "      <td>587.878418</td>\n",
       "      <td>1152.607544</td>\n",
       "      <td>587.920410</td>\n",
       "      <td>1151.879150</td>\n",
       "      <td>587.945007</td>\n",
       "      <td>...</td>\n",
       "      <td>588.656860</td>\n",
       "      <td>1135.403320</td>\n",
       "      <td>588.664429</td>\n",
       "      <td>1134.632080</td>\n",
       "      <td>588.677979</td>\n",
       "      <td>1133.911865</td>\n",
       "      <td>588.702026</td>\n",
       "      <td>1133.058228</td>\n",
       "      <td>588.725037</td>\n",
       "      <td>1132.309326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>9905</td>\n",
       "      <td>1755.523560</td>\n",
       "      <td>444.354431</td>\n",
       "      <td>1755.317505</td>\n",
       "      <td>444.637787</td>\n",
       "      <td>1755.165649</td>\n",
       "      <td>444.898285</td>\n",
       "      <td>1754.985107</td>\n",
       "      <td>445.200470</td>\n",
       "      <td>1754.822388</td>\n",
       "      <td>...</td>\n",
       "      <td>1751.256592</td>\n",
       "      <td>450.692841</td>\n",
       "      <td>1751.105347</td>\n",
       "      <td>450.904938</td>\n",
       "      <td>1750.932007</td>\n",
       "      <td>451.151123</td>\n",
       "      <td>1750.773804</td>\n",
       "      <td>451.356842</td>\n",
       "      <td>1750.617310</td>\n",
       "      <td>451.607178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>9910</td>\n",
       "      <td>574.456909</td>\n",
       "      <td>1288.706055</td>\n",
       "      <td>574.272400</td>\n",
       "      <td>1288.465210</td>\n",
       "      <td>574.084900</td>\n",
       "      <td>1288.258179</td>\n",
       "      <td>573.893677</td>\n",
       "      <td>1288.012329</td>\n",
       "      <td>573.695740</td>\n",
       "      <td>...</td>\n",
       "      <td>567.915527</td>\n",
       "      <td>1282.440674</td>\n",
       "      <td>567.595764</td>\n",
       "      <td>1282.213989</td>\n",
       "      <td>567.269592</td>\n",
       "      <td>1281.899902</td>\n",
       "      <td>566.970825</td>\n",
       "      <td>1281.716187</td>\n",
       "      <td>566.589111</td>\n",
       "      <td>1281.406494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>9918</td>\n",
       "      <td>584.656433</td>\n",
       "      <td>1164.758545</td>\n",
       "      <td>584.813965</td>\n",
       "      <td>1163.718872</td>\n",
       "      <td>584.859924</td>\n",
       "      <td>1162.650146</td>\n",
       "      <td>584.938538</td>\n",
       "      <td>1161.605591</td>\n",
       "      <td>584.984131</td>\n",
       "      <td>...</td>\n",
       "      <td>586.316650</td>\n",
       "      <td>1139.506226</td>\n",
       "      <td>586.356812</td>\n",
       "      <td>1138.541016</td>\n",
       "      <td>586.377319</td>\n",
       "      <td>1137.670898</td>\n",
       "      <td>586.390869</td>\n",
       "      <td>1136.580688</td>\n",
       "      <td>586.427734</td>\n",
       "      <td>1135.741577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID           v1           v2           v3           v4           v5  \\\n",
       "0     10002  1714.842163   337.056671  1715.699097   338.048157  1716.643677   \n",
       "1     10015   725.461243  1229.644653   725.351440  1229.402222   725.264954   \n",
       "2     10019   574.294495  1244.495972   574.499207  1244.314697   574.723267   \n",
       "3     10028  1691.317017   315.481720  1691.931030   316.177155  1692.618164   \n",
       "4      1003  2122.486816   677.054199  2121.262207   675.803833  2119.931641   \n",
       "...     ...          ...          ...          ...          ...          ...   \n",
       "3195   9897   256.462372   805.223816   256.681396   804.911438   256.906006   \n",
       "3196     99   587.784851  1154.007202   587.875916  1153.310669   587.878418   \n",
       "3197   9905  1755.523560   444.354431  1755.317505   444.637787  1755.165649   \n",
       "3198   9910   574.456909  1288.706055   574.272400  1288.465210   574.084900   \n",
       "3199   9918   584.656433  1164.758545   584.813965  1163.718872   584.859924   \n",
       "\n",
       "               v6           v7           v8           v9  ...          v51  \\\n",
       "0      338.915985  1717.606934   339.867767  1718.577759  ...  1738.091431   \n",
       "1     1229.104858   725.148499  1228.881226   724.991699  ...   721.353149   \n",
       "2     1244.158203   574.912048  1243.989624   575.132629  ...   579.535645   \n",
       "3      316.777557  1693.320312   317.445312  1694.024536  ...  1708.731079   \n",
       "4      674.727417  2118.570068   673.543152  2117.205322  ...  2089.961426   \n",
       "...           ...          ...          ...          ...  ...          ...   \n",
       "3195   804.566833   257.122406   804.231201   257.328644  ...   260.885498   \n",
       "3196  1152.607544   587.920410  1151.879150   587.945007  ...   588.656860   \n",
       "3197   444.898285  1754.985107   445.200470  1754.822388  ...  1751.256592   \n",
       "3198  1288.258179   573.893677  1288.012329   573.695740  ...   567.915527   \n",
       "3199  1162.650146   584.938538  1161.605591   584.984131  ...   586.316650   \n",
       "\n",
       "              v52          v53          v54          v55          v56  \\\n",
       "0      359.684631  1739.020752   360.514374  1739.964355   361.383942   \n",
       "1     1224.213135   721.075500  1223.997559   720.779297  1223.956665   \n",
       "2     1238.270874   579.729431  1237.927734   579.898865  1237.576904   \n",
       "3      331.712708  1709.437012   332.327057  1710.143433   332.959167   \n",
       "4      649.322632  2088.695312   648.320862  2087.381592   647.251953   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "3195   794.862732   261.016510   794.362244   261.129303   793.891174   \n",
       "3196  1135.403320   588.664429  1134.632080   588.677979  1133.911865   \n",
       "3197   450.692841  1751.105347   450.904938  1750.932007   451.151123   \n",
       "3198  1282.440674   567.595764  1282.213989   567.269592  1281.899902   \n",
       "3199  1139.506226   586.356812  1138.541016   586.377319  1137.670898   \n",
       "\n",
       "              v57          v58          v59          v60  \n",
       "0     1740.915405   362.252716  1741.877075   363.102844  \n",
       "1      720.498901  1223.598145   720.229675  1223.427124  \n",
       "2      580.119995  1237.219849   580.334167  1236.833130  \n",
       "3     1710.896484   333.608765  1711.608154   334.212708  \n",
       "4     2086.074951   646.237854  2084.768311   645.246948  \n",
       "...           ...          ...          ...          ...  \n",
       "3195   261.299316   793.375854   261.450745   792.865601  \n",
       "3196   588.702026  1133.058228   588.725037  1132.309326  \n",
       "3197  1750.773804   451.356842  1750.617310   451.607178  \n",
       "3198   566.970825  1281.716187   566.589111  1281.406494  \n",
       "3199   586.390869  1136.580688   586.427734  1135.741577  \n",
       "\n",
       "[3200 rows x 61 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ID'] = submission['ID']\n",
    "cols = df.columns[-1:].tolist() + df.columns[:-1].tolist()\n",
    "df = df[cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def save_submission(df, filename):\n",
    "    filename = filename + \"_\" + str(datetime.now()) + \".csv\"\n",
    "    file_path = os.path.join(submission_dir, filename)\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(df, \"DeepConvMLP3layers + normalized_position + epoch8 + batch16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
