{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./new_train/new_train\"\n",
    "test_path = \"./new_val_in/new_val_in\"\n",
    "submission_path = \"./sample_submission.csv\"\n",
    "submission_dir = \"./submissions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Val Split\n",
    "TRAIN_SIZE = 0.85\n",
    "VAL_SIZE = 0.15\n",
    "\n",
    "# training config\n",
    "NUM_EPOCH = 20\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "EARLY_STOP_MAX = 6\n",
    "\n",
    "# feature engineering configs\n",
    "NEARBY_DISTANCE_THRESHOLD = 50.0  # Distance threshold to call a track as neighbor\n",
    "DEFAULT_MIN_DIST_FRONT_AND_BACK = 100. # default distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import optuna\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argoverse_forecasting.utils.social_features_utils import SocialFeaturesUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ArgoverseDataset(data_path=train_path)\n",
    "test = ArgoverseDataset(data_path=test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(TRAIN_SIZE * len(train))\n",
    "val_size = len(train) - train_size\n",
    "train, val = torch.utils.data.random_split(train, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_track(scene, mode=\"train\"):\n",
    "    agent_idx = np.where(scene[\"agent_id\"] == np.unique(scene[\"track_id\"].flatten()))[0][0]\n",
    "    agent_traj = scene['p_in'][agent_idx]\n",
    "    if mode == \"test\":\n",
    "        return agent_traj\n",
    "    else:\n",
    "        agent_traj = np.concatenate([agent_traj, scene['p_out'][agent_idx]])\n",
    "    return agent_traj\n",
    "\n",
    "def get_social_tracks(scene, mode=\"train\"):\n",
    "    agent_idx = np.where(scene[\"agent_id\"] == np.unique(scene[\"track_id\"].flatten()))[0][0]\n",
    "    social_masks = scene[\"car_mask\"].flatten()\n",
    "    social_masks[agent_idx] = 0\n",
    "    social_trajs = scene['p_in'][social_masks.astype(bool)]\n",
    "    \n",
    "    if mode == \"test\":\n",
    "        return social_trajs\n",
    "    else:\n",
    "        return np.concatenate([social_trajs, scene['p_out'][social_masks.astype(bool)]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate social features\n",
    "def get_social_features(scene, mode=\"train\"):\n",
    "    \"\"\"\n",
    "    Extract social features:\n",
    "        1. number of neighbors\n",
    "        2. min front/back distance at each timestamp\n",
    "    \"\"\"\n",
    "    agent_track = get_agent_track(scene, mode)\n",
    "    social_tracks = get_social_tracks(scene, mode)\n",
    "    # compute social features\n",
    "    if mode == \"test\":\n",
    "        num_neighbors = count_num_neighbors(agent_track, social_tracks)\n",
    "    else:\n",
    "        num_neighbors = count_num_neighbors(agent_track[:19], social_tracks[:, :19])\n",
    "#     min_dist = get_min_distance_front_and_back(agent_traj, social_trajs)\n",
    "#     return np.concatenate((num_neighbors, min_dist), axis=1)\n",
    "#     social_features_utils = SocialFeaturesUtils()\n",
    "#     min_dist_front_back = social_features_utils.get_min_distance_front_and_back(\n",
    "#         agent_track=agent_track,\n",
    "#         social_tracks=social_tracks,\n",
    "#         obs_len=19,\n",
    "#         raw_data_format={\"X\": 0, \"Y\": 1}\n",
    "#     )\n",
    "    \n",
    "#     return np.concatenate((num_neighbors, min_dist_front_back), axis=1)\n",
    "    return num_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_num_neighbors(agent_traj, social_trajs):\n",
    "    \"\"\"\n",
    "    Calculate euclidean distance between agent_traj and social_trajs\n",
    "    if distance is less than NEARBY_DISTANCE_THRESHOLD, then num_neighbors++\n",
    "    \n",
    "    Args:\n",
    "        agent_traj (np.array): data for agent trajectory\n",
    "        social_trajs (np.array): array of other agents' trajectories\n",
    "    Returns:\n",
    "        (np.array): \n",
    "    \"\"\"\n",
    "    num_neighbors = []\n",
    "    dist = np.sqrt(\n",
    "        (social_trajs[:, :, 0] - agent_traj[:, 0])**2 \n",
    "        + (social_trajs[:, :, 1] - agent_traj[:, 1])**2\n",
    "    ).T\n",
    "    num_neighbors = np.sum(dist < NEARBY_DISTANCE_THRESHOLD, axis=1)\n",
    "    return num_neighbors.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp, out = [], []\n",
    "    for scene in batch:\n",
    "        agent_idx = np.where(scene[\"agent_id\"] == np.unique(scene[\"track_id\"].flatten()))[0][0]\n",
    "        social_features = get_social_features(scene)\n",
    "        inp.append(np.hstack([scene['p_in'][agent_idx], social_features])) # scene['v_in'][agent_idx],\n",
    "        out.append(scene['p_out'][agent_idx])\n",
    "\n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.FloatTensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "def my_test_collect(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp, out = [], []\n",
    "    for scene in batch:\n",
    "        agent_idx = np.where(scene[\"agent_id\"] == np.unique(scene[\"track_id\"].flatten()))[0][0]\n",
    "        social_features = get_social_features(scene, mode=\"test\")\n",
    "        inp.append(np.hstack([scene['p_in'][agent_idx], social_features])) #  scene['v_in'][agent_idx],\n",
    "        out.append([])\n",
    "\n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.FloatTensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle = False, collate_fn=my_collate, num_workers=0)\n",
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle = False, collate_fn=my_collate, num_workers=0)\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE, shuffle = False, collate_fn=my_test_collect, num_workers=0)\n",
    "# exmaple = iter(val_loader)\n",
    "# exmaple.next()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v51</th>\n",
       "      <th>v52</th>\n",
       "      <th>v53</th>\n",
       "      <th>v54</th>\n",
       "      <th>v55</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58</th>\n",
       "      <th>v59</th>\n",
       "      <th>v60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>9897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>9905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>9910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>9918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID   v1   v2   v3   v4   v5   v6   v7   v8   v9  ...  v51  v52  v53  \\\n",
       "0     10002  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1     10015  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2     10019  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3     10028  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      1003  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "3195   9897  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3196     99  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3197   9905  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3198   9910  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3199   9918  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "      v54  v55  v56  v57  v58  v59  v60  \n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "3195  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3196  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3197  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3198  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3199  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[3200 rows x 61 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(submission_path)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_position(inp, out=None):\n",
    "    \"\"\"calculate position difference\"\"\"\n",
    "    input_length = inp.shape[1]\n",
    "    p_in_0 = copy.deepcopy(inp[:, 0, :2])\n",
    "    \n",
    "    \n",
    "    if out is not None:\n",
    "        out = copy.deepcopy(out)\n",
    "        output_length = out.shape[1]\n",
    "        for i in range(output_length - 1, 0, -1):\n",
    "            out[:, i, :2] = out[:, i, :2] - out[:, i - 1, :2]\n",
    "        out[:, 0, :2] = out[:, 0, :2] - inp[:, -1, :2]\n",
    "        \n",
    "    for i in range(input_length - 1, 0, -1):\n",
    "        inp[:, i, :2] = inp[:, i, :2] - inp[:, i - 1, :2]\n",
    "    inp[:, 0, :] = 0\n",
    "    \n",
    "    if out is not None:\n",
    "        return inp, out, p_in_0\n",
    "    \n",
    "    return inp, p_in_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absolute_position(inp, out, p_in_0, return_pred_only=False):\n",
    "    \"\"\"position inverse difference\"\"\"\n",
    "    inp[:, 0, :2] = p_in_0\n",
    "    for i in range(1, inp.shape[1]):\n",
    "        inp[:, i, :2] = inp[:, i, :2] + inp[:, i - 1, :2]\n",
    "\n",
    "    out[:, 0, :2] = out[:, 0, :2] + inp[:, -1, :2]\n",
    "    for i in range(1, out.shape[1]):\n",
    "        out[:, i, :2] = out[:, i, :2] + out[:, i - 1, :2]\n",
    "    \n",
    "    if return_pred_only:\n",
    "        return out\n",
    "    \n",
    "    return inp, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(torch.nn.Module):\n",
    "    \"\"\"RMSE Loss\"\"\"\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = torch.sqrt(criterion(yhat, y))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training config\n",
    "ROLLOUT_LEN = 30\n",
    "\n",
    "# model config\n",
    "INPUT_SIZE = 5\n",
    "EMBEDDING_SIZE = 8\n",
    "HIDDEN_SIZE = 16\n",
    "OUTPUT_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size,\n",
    "                 embedding_size=EMBEDDING_SIZE, \n",
    "                 num_layers=3, \n",
    "                 hidden_size=HIDDEN_SIZE):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.linear = nn.Linear(input_size, embedding_size)\n",
    "        self.lstms = nn.ModuleList([nn.LSTMCell(\n",
    "            embedding_size if i == 0 else hidden_size, hidden_size\n",
    "        ) for i in range(self.num_layers)])\n",
    "           \n",
    "#         self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers=self.num_layers)\n",
    "\n",
    "    def init_hidden(self, batch_size, hidden_size, num_layers):\n",
    "        \"\"\"Return a list of initial hidden states\"\"\"\n",
    "        # Initialize encoder hidden state\n",
    "        hiddens = []\n",
    "        for i in range(num_layers):\n",
    "            h_0 = torch.zeros(batch_size, hidden_size).to(device)\n",
    "            c_0 = torch.zeros(batch_size, hidden_size).to(device)\n",
    "            nn.init.xavier_normal_(h_0)\n",
    "            nn.init.xavier_normal_(c_0)\n",
    "            hiddens.append((h_0, c_0))\n",
    "        return hiddens\n",
    "    \n",
    "    def forward(self, X, last_hidden_states=None):\n",
    "        if last_hidden_states is None:\n",
    "            last_hidden_states = self.init_hidden(X.shape[0], self.hidden_size, self.num_layers)\n",
    "        \n",
    "        # original: (batch_size, seq_len, input_size)\n",
    "        # expected: (seq_len, batch_size, input_size)\n",
    "        embedded = F.relu(self.linear(X))\n",
    "        hiddent_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            hidden_state = self.lstms[i](embedded if i == 0 else hidden_state[0], last_hidden_states[i])\n",
    "            hiddent_states.append(hidden_state)\n",
    "        return hiddent_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        embedding_size=EMBEDDING_SIZE,\n",
    "        hidden_size=HIDDEN_SIZE, \n",
    "        num_layers=3,\n",
    "        output_size=OUTPUT_SIZE\n",
    "    ):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.linear1 = nn.Linear(output_size, embedding_size)\n",
    "        self.lstms = nn.ModuleList([nn.LSTMCell(\n",
    "            embedding_size if i == 0 else hidden_size, hidden_size\n",
    "        ) for i in range(self.num_layers)])\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, decoder_input, last_encoder_hiddens):\n",
    "        embedded = self.dropout(F.relu(self.linear1(decoder_input)))\n",
    "        hidden_states = []\n",
    "        for i, lstm in enumerate(self.lstms):\n",
    "            hidden = lstm(embedded if i == 0 else hidden[0], last_encoder_hiddens[i])\n",
    "            hidden_states.append(hidden)\n",
    "        output = self.linear2(hidden[0])\n",
    "        return output, hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_validation(val_loader, encoder, decoder, normalize=False):\n",
    "    loss_fn = RMSELoss()\n",
    "    \n",
    "    for i_batch, batch_data in enumerate(val_loader):\n",
    "        inp, out = batch_data\n",
    "        inp = inp.to(device)\n",
    "        out = out.to(device)\n",
    "        \n",
    "        # eval mode\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        \n",
    "        # Encoder\n",
    "        batch_size = inp.shape[0]\n",
    "        input_length = inp.shape[1]\n",
    "        output_length = out.shape[1]\n",
    "        input_shape = inp.shape[2]\n",
    "\n",
    "        # Initialize losses\n",
    "        loss = 0\n",
    "\n",
    "        # Get relative position\n",
    "        initial_p_in = inp[:, 0, :2].detach().clone()\n",
    "        inp[:, :, :2] = inp[:, :, :2] - initial_p_in[:, None]\n",
    "#         inp, processed_out, p_in_0 = get_relative_position(inp, out)\n",
    "\n",
    "        # Encode observed trajectory\n",
    "        encoder_hidden = None\n",
    "        for i in range(input_length):\n",
    "            encoder_input = inp[:, i, :]\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "\n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "#         prev_p = p_in_0\n",
    "        for i in range(output_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, encoder_hidden)\n",
    "\n",
    "            # Update loss\n",
    "            loss += loss_fn(decoder_output[:, :2], out[:, i, :2] - initial_p_in)\n",
    "#             pred_out = decoder_output[:, :2] + prev_p\n",
    "#             loss += loss_fn(pred_out, out[:, i, :2])\n",
    "#             prev_p = pred_out\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        loss = loss / output_length\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "encoder = EncoderLSTM(3)\n",
    "decoder = DecoderLSTM()\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "loss_fn = RMSELoss()\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=LEARNING_RATE)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, batch 0/2736, Training loss: 23.8862, Val loss: 23.1506\n",
      "Epoch 1/20, batch 400/2736, Training loss: 17.6191, Val loss: 17.8455\n",
      "Epoch 1/20, batch 800/2736, Training loss: 15.8906, Val loss: 16.2224\n",
      "Epoch 1/20, batch 1200/2736, Training loss: 14.5496, Val loss: 15.9050\n",
      "Epoch 1/20, batch 1600/2736, Training loss: 11.1741, Val loss: 14.6491\n",
      "Epoch 1/20, batch 2000/2736, Training loss: 10.7174, Val loss: 13.3682\n",
      "Epoch 1/20, batch 2400/2736, Training loss: 7.1087, Val loss: 12.1975\n",
      "Epoch 2/20, batch 0/2736, Training loss: 7.8157, Val loss: 11.8589\n",
      "Epoch 2/20, batch 400/2736, Training loss: 6.1122, Val loss: 11.4944\n",
      "Epoch 2/20, batch 800/2736, Training loss: 5.0937, Val loss: 11.2545\n",
      "Epoch 2/20, batch 1200/2736, Training loss: 4.7789, Val loss: 11.2387\n",
      "Epoch 2/20, batch 1600/2736, Training loss: 4.4533, Val loss: 11.1336\n",
      "Epoch 2/20, batch 2000/2736, Training loss: 4.4217, Val loss: 10.8512\n",
      "Epoch 2/20, batch 2400/2736, Training loss: 3.3292, Val loss: 10.7126\n",
      "Epoch 3/20, batch 0/2736, Training loss: 4.0129, Val loss: 10.6529\n",
      "Epoch 3/20, batch 400/2736, Training loss: 3.1407, Val loss: 10.8029\n",
      "Epoch 3/20, batch 800/2736, Training loss: 3.2953, Val loss: 10.4403\n",
      "Epoch 3/20, batch 1200/2736, Training loss: 2.9182, Val loss: 10.6625\n",
      "Epoch 3/20, batch 1600/2736, Training loss: 3.3630, Val loss: 10.5766\n",
      "Epoch 3/20, batch 2000/2736, Training loss: 3.0075, Val loss: 10.3654\n",
      "Epoch 3/20, batch 2400/2736, Training loss: 2.7008, Val loss: 10.4754\n",
      "Epoch 4/20, batch 0/2736, Training loss: 3.5122, Val loss: 10.3803\n",
      "Epoch 4/20, batch 400/2736, Training loss: 2.5727, Val loss: 10.6774\n",
      "Epoch 4/20, batch 800/2736, Training loss: 2.9424, Val loss: 10.3257\n",
      "Epoch 4/20, batch 1200/2736, Training loss: 2.5273, Val loss: 10.6617\n",
      "Epoch 4/20, batch 1600/2736, Training loss: 2.9555, Val loss: 10.5200\n",
      "Epoch 4/20, batch 2000/2736, Training loss: 2.4386, Val loss: 10.3461\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a189bb096c4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprev_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_decreasing_loss_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-c756740da99c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpkl_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpkl_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "prev_loss, non_decreasing_loss_cnt = -float(\"inf\"), 0\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for i_batch, batch_data in enumerate(train_loader):\n",
    "        inp, out = batch_data\n",
    "        inp = inp.to(device)\n",
    "        out = out.to(device)\n",
    "        \n",
    "        # Set to train mode\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        # Initialize losses\n",
    "        loss = 0\n",
    "\n",
    "        # Encoder\n",
    "        batch_size = inp.shape[0]\n",
    "        input_length = inp.shape[1]  # expected: 19\n",
    "        output_length = out.shape[1]  # expected: 30\n",
    "        input_shape = inp.shape[2]\n",
    "        total_length = input_length + output_length  # expected: 49\n",
    "\n",
    "        # Get relative position  \n",
    "        initial_p_in = inp[:, 0, :2].detach().clone()\n",
    "        inp[:, :, :2] = inp[:, :, :2] - initial_p_in[:, None]\n",
    "        \n",
    "#         inp, processed_out, p_in_0 = get_relative_position(inp, out)\n",
    "#         inp_cols = [0, 1, 4]\n",
    "        # Encode observed trajectory\n",
    "        encoder_hidden = None\n",
    "        for i in range(input_length):\n",
    "            encoder_input = inp[:, i, :]\n",
    "            encoder_hidden = encoder(encoder_input, encoder_hidden)\n",
    "#         encoder_hidden = encoder(inp)\n",
    "        \n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "#         prev_p = p_in_0\n",
    "        for i in range(output_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            # Update loss\n",
    "            loss += loss_fn(decoder_output[:, :2], out[:, i, :2] - initial_p_in)\n",
    "            \n",
    "#             pred_out = decoder_output[:, :2] + prev_p\n",
    "#             loss += loss_fn(decoder_output[:, :2], processed_out[:, i, :2])\n",
    "#             prev_p = pred_out\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            decoder_input = decoder_output\n",
    "\n",
    "        # Get average loss for pred_len\n",
    "        loss = loss / output_length\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "            \n",
    "        if i_batch % 400 == 0:\n",
    "            # print training loss\n",
    "            training_loss = loss.item()\n",
    "            train_losses.append(training_loss)\n",
    "        \n",
    "            # validate \n",
    "            with torch.no_grad():\n",
    "                val_loss = check_validation(val_loader, encoder, decoder, normalize=False)\n",
    "#                 val_losses.append(val_loss.item())  \n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{NUM_EPOCH}, batch {i_batch}/{len(train_loader)}, \"\\\n",
    "                    + f\"Training loss: {training_loss:.4f}\"\\\n",
    "                    + f\", Val loss: {val_loss.item():.4f}\")\n",
    "            \n",
    "            # early stop\n",
    "#             if val_loss.item() > prev_loss:\n",
    "#                 non_decreasing_loss_cnt += 1\n",
    "#             else:\n",
    "#                 non_decreasing_loss_cnt = 0\n",
    "#                 prev_loss = val_loss.item()\n",
    "            \n",
    "#             if non_decreasing_loss_cnt >= EARLY_STOP_MAX:\n",
    "#                 break \n",
    "                \n",
    "#     if non_decreasing_loss_cnt >= EARLY_STOP_MAX:\n",
    "#         break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in decoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "pred_p_out = []\n",
    "all_zeros_ix = []\n",
    "with torch.no_grad():\n",
    "    for i_batch, batch_data in enumerate(test_loader):\n",
    "        inp, out = batch_data\n",
    "        inp = inp.to(device)\n",
    "                    \n",
    "        # Set to eval mode\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        # Encoder\n",
    "        batch_size = inp.shape[0]\n",
    "        input_length = inp.shape[1]\n",
    "        input_shape = inp.shape[2]\n",
    "\n",
    "        # Get relative position\n",
    "        initial_p_in = inp[:, 0, :2].detach().clone()\n",
    "        inp[:, :, :2] = inp[:, :, :2] - initial_p_in[:, None]\n",
    "#         inp, p_in_0 = get_relative_position(inp)\n",
    "        \n",
    "        # Encode observed trajectory\n",
    "        for i in range(input_length):\n",
    "            encoder_input = inp[:, i, :]\n",
    "            encoder_hidden = encoder(encoder_input)\n",
    "\n",
    "        # Initialize decoder input with last coordinate in encoder\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = encoder_input[:, :2]\n",
    "        decoder_outputs = torch.zeros((len(inp), 30, 2))\n",
    "\n",
    "        # Decode hidden state in future trajectory\n",
    "        for i in range(30):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            decoder_outputs[:, i, :] = decoder_output + initial_p_in\n",
    "\n",
    "            # Use own predictions as inputs at next step\n",
    "            decoder_input = decoder_output\n",
    "            \n",
    "        # predicted_p_out\n",
    "#         out = get_absolute_position(inp, decoder_outputs.to(device), p_in_0, return_pred_only=True)\n",
    "        pred_p_out.append(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1718.1674,  349.4510],\n",
       "         [1721.1884,  355.0500],\n",
       "         [1723.6831,  359.9641],\n",
       "         ...,\n",
       "         [1704.9786,  420.0189],\n",
       "         [1704.4425,  420.3767],\n",
       "         [1704.0544,  420.6542]],\n",
       "\n",
       "        [[ 728.6434, 1227.5297],\n",
       "         [ 726.5579, 1223.2423],\n",
       "         [ 724.8978, 1219.6112],\n",
       "         ...,\n",
       "         [ 712.0584, 1162.3185],\n",
       "         [ 711.7137, 1161.3962],\n",
       "         [ 711.4163, 1160.6118]],\n",
       "\n",
       "        [[ 585.1850, 1249.8937],\n",
       "         [ 586.6434, 1251.0968],\n",
       "         [ 587.8399, 1252.3562],\n",
       "         ...,\n",
       "         [ 610.0473, 1296.7715],\n",
       "         [ 610.4717, 1298.2325],\n",
       "         [ 610.8462, 1299.6322]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1757.1272,  444.5212],\n",
       "         [1756.6501,  447.2381],\n",
       "         [1756.0437,  449.5727],\n",
       "         ...,\n",
       "         [1730.6949,  472.9033],\n",
       "         [1729.5703,  473.2854],\n",
       "         [1728.4368,  473.6598]],\n",
       "\n",
       "        [[ 583.9580, 1288.6854],\n",
       "         [ 583.2294, 1287.1013],\n",
       "         [ 582.3897, 1285.6603],\n",
       "         ...,\n",
       "         [ 570.7696, 1261.6725],\n",
       "         [ 570.4316, 1261.5396],\n",
       "         [ 570.0875, 1261.4751]],\n",
       "\n",
       "        [[ 583.6014, 1154.6998],\n",
       "         [ 582.8892, 1147.0272],\n",
       "         [ 581.7860, 1141.2693],\n",
       "         ...,\n",
       "         [ 568.3837, 1102.9795],\n",
       "         [ 568.3807, 1102.9993],\n",
       "         [ 568.3916, 1103.0281]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_p_out = torch.FloatTensor(len(test_loader), 30, 2)\n",
    "torch.cat(pred_p_out, out=predicted_p_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v51</th>\n",
       "      <th>v52</th>\n",
       "      <th>v53</th>\n",
       "      <th>v54</th>\n",
       "      <th>v55</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58</th>\n",
       "      <th>v59</th>\n",
       "      <th>v60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1718.167358</td>\n",
       "      <td>349.451019</td>\n",
       "      <td>1721.188354</td>\n",
       "      <td>355.049988</td>\n",
       "      <td>1723.683105</td>\n",
       "      <td>359.964111</td>\n",
       "      <td>1725.946655</td>\n",
       "      <td>364.665222</td>\n",
       "      <td>1728.003052</td>\n",
       "      <td>369.199066</td>\n",
       "      <td>...</td>\n",
       "      <td>1706.635620</td>\n",
       "      <td>418.986298</td>\n",
       "      <td>1705.698486</td>\n",
       "      <td>419.561737</td>\n",
       "      <td>1704.978638</td>\n",
       "      <td>420.018860</td>\n",
       "      <td>1704.442505</td>\n",
       "      <td>420.376678</td>\n",
       "      <td>1704.054443</td>\n",
       "      <td>420.654175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>728.643372</td>\n",
       "      <td>1227.529663</td>\n",
       "      <td>726.557922</td>\n",
       "      <td>1223.242310</td>\n",
       "      <td>724.897827</td>\n",
       "      <td>1219.611206</td>\n",
       "      <td>723.590637</td>\n",
       "      <td>1216.297607</td>\n",
       "      <td>722.560852</td>\n",
       "      <td>1213.222290</td>\n",
       "      <td>...</td>\n",
       "      <td>712.900696</td>\n",
       "      <td>1164.670898</td>\n",
       "      <td>712.451050</td>\n",
       "      <td>1163.398804</td>\n",
       "      <td>712.058411</td>\n",
       "      <td>1162.318481</td>\n",
       "      <td>711.713684</td>\n",
       "      <td>1161.396240</td>\n",
       "      <td>711.416321</td>\n",
       "      <td>1160.611816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>585.184998</td>\n",
       "      <td>1249.893677</td>\n",
       "      <td>586.643433</td>\n",
       "      <td>1251.096802</td>\n",
       "      <td>587.839905</td>\n",
       "      <td>1252.356201</td>\n",
       "      <td>588.974243</td>\n",
       "      <td>1253.730713</td>\n",
       "      <td>590.088745</td>\n",
       "      <td>1255.198364</td>\n",
       "      <td>...</td>\n",
       "      <td>609.061584</td>\n",
       "      <td>1293.652100</td>\n",
       "      <td>609.576538</td>\n",
       "      <td>1295.245361</td>\n",
       "      <td>610.047302</td>\n",
       "      <td>1296.771484</td>\n",
       "      <td>610.471680</td>\n",
       "      <td>1298.232544</td>\n",
       "      <td>610.846191</td>\n",
       "      <td>1299.632202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1711.302490</td>\n",
       "      <td>335.212433</td>\n",
       "      <td>1717.384888</td>\n",
       "      <td>341.419952</td>\n",
       "      <td>1722.428955</td>\n",
       "      <td>347.357880</td>\n",
       "      <td>1726.825317</td>\n",
       "      <td>353.189972</td>\n",
       "      <td>1730.555908</td>\n",
       "      <td>358.519531</td>\n",
       "      <td>...</td>\n",
       "      <td>1742.168213</td>\n",
       "      <td>386.077820</td>\n",
       "      <td>1741.931152</td>\n",
       "      <td>386.440338</td>\n",
       "      <td>1741.685059</td>\n",
       "      <td>386.775360</td>\n",
       "      <td>1741.431641</td>\n",
       "      <td>387.085114</td>\n",
       "      <td>1741.172485</td>\n",
       "      <td>387.371765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2127.204346</td>\n",
       "      <td>669.752380</td>\n",
       "      <td>2122.890869</td>\n",
       "      <td>662.372009</td>\n",
       "      <td>2120.180664</td>\n",
       "      <td>656.191040</td>\n",
       "      <td>2118.242920</td>\n",
       "      <td>650.470276</td>\n",
       "      <td>2117.015381</td>\n",
       "      <td>645.193726</td>\n",
       "      <td>...</td>\n",
       "      <td>2117.430176</td>\n",
       "      <td>625.168640</td>\n",
       "      <td>2117.488770</td>\n",
       "      <td>625.222778</td>\n",
       "      <td>2117.552979</td>\n",
       "      <td>625.284363</td>\n",
       "      <td>2117.621338</td>\n",
       "      <td>625.351379</td>\n",
       "      <td>2117.693115</td>\n",
       "      <td>625.422119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            v1           v2           v3           v4           v5  \\\n",
       "0  1718.167358   349.451019  1721.188354   355.049988  1723.683105   \n",
       "1   728.643372  1227.529663   726.557922  1223.242310   724.897827   \n",
       "2   585.184998  1249.893677   586.643433  1251.096802   587.839905   \n",
       "3  1711.302490   335.212433  1717.384888   341.419952  1722.428955   \n",
       "4  2127.204346   669.752380  2122.890869   662.372009  2120.180664   \n",
       "\n",
       "            v6           v7           v8           v9          v10  ...  \\\n",
       "0   359.964111  1725.946655   364.665222  1728.003052   369.199066  ...   \n",
       "1  1219.611206   723.590637  1216.297607   722.560852  1213.222290  ...   \n",
       "2  1252.356201   588.974243  1253.730713   590.088745  1255.198364  ...   \n",
       "3   347.357880  1726.825317   353.189972  1730.555908   358.519531  ...   \n",
       "4   656.191040  2118.242920   650.470276  2117.015381   645.193726  ...   \n",
       "\n",
       "           v51          v52          v53          v54          v55  \\\n",
       "0  1706.635620   418.986298  1705.698486   419.561737  1704.978638   \n",
       "1   712.900696  1164.670898   712.451050  1163.398804   712.058411   \n",
       "2   609.061584  1293.652100   609.576538  1295.245361   610.047302   \n",
       "3  1742.168213   386.077820  1741.931152   386.440338  1741.685059   \n",
       "4  2117.430176   625.168640  2117.488770   625.222778  2117.552979   \n",
       "\n",
       "           v56          v57          v58          v59          v60  \n",
       "0   420.018860  1704.442505   420.376678  1704.054443   420.654175  \n",
       "1  1162.318481   711.713684  1161.396240   711.416321  1160.611816  \n",
       "2  1296.771484   610.471680  1298.232544   610.846191  1299.632202  \n",
       "3   386.775360  1741.431641   387.085114  1741.172485   387.371765  \n",
       "4   625.284363  2117.621338   625.351379  2117.693115   625.422119  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make final submission dataframe\n",
    "df = pd.DataFrame(predicted_p_out.view(3200, -1).cpu().numpy(), columns=[f\"v{i}\" for i in range(1, 61)])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v51</th>\n",
       "      <th>v52</th>\n",
       "      <th>v53</th>\n",
       "      <th>v54</th>\n",
       "      <th>v55</th>\n",
       "      <th>v56</th>\n",
       "      <th>v57</th>\n",
       "      <th>v58</th>\n",
       "      <th>v59</th>\n",
       "      <th>v60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>1718.167358</td>\n",
       "      <td>349.451019</td>\n",
       "      <td>1721.188354</td>\n",
       "      <td>355.049988</td>\n",
       "      <td>1723.683105</td>\n",
       "      <td>359.964111</td>\n",
       "      <td>1725.946655</td>\n",
       "      <td>364.665222</td>\n",
       "      <td>1728.003052</td>\n",
       "      <td>...</td>\n",
       "      <td>1706.635620</td>\n",
       "      <td>418.986298</td>\n",
       "      <td>1705.698486</td>\n",
       "      <td>419.561737</td>\n",
       "      <td>1704.978638</td>\n",
       "      <td>420.018860</td>\n",
       "      <td>1704.442505</td>\n",
       "      <td>420.376678</td>\n",
       "      <td>1704.054443</td>\n",
       "      <td>420.654175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10015</td>\n",
       "      <td>728.643372</td>\n",
       "      <td>1227.529663</td>\n",
       "      <td>726.557922</td>\n",
       "      <td>1223.242310</td>\n",
       "      <td>724.897827</td>\n",
       "      <td>1219.611206</td>\n",
       "      <td>723.590637</td>\n",
       "      <td>1216.297607</td>\n",
       "      <td>722.560852</td>\n",
       "      <td>...</td>\n",
       "      <td>712.900696</td>\n",
       "      <td>1164.670898</td>\n",
       "      <td>712.451050</td>\n",
       "      <td>1163.398804</td>\n",
       "      <td>712.058411</td>\n",
       "      <td>1162.318481</td>\n",
       "      <td>711.713684</td>\n",
       "      <td>1161.396240</td>\n",
       "      <td>711.416321</td>\n",
       "      <td>1160.611816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10019</td>\n",
       "      <td>585.184998</td>\n",
       "      <td>1249.893677</td>\n",
       "      <td>586.643433</td>\n",
       "      <td>1251.096802</td>\n",
       "      <td>587.839905</td>\n",
       "      <td>1252.356201</td>\n",
       "      <td>588.974243</td>\n",
       "      <td>1253.730713</td>\n",
       "      <td>590.088745</td>\n",
       "      <td>...</td>\n",
       "      <td>609.061584</td>\n",
       "      <td>1293.652100</td>\n",
       "      <td>609.576538</td>\n",
       "      <td>1295.245361</td>\n",
       "      <td>610.047302</td>\n",
       "      <td>1296.771484</td>\n",
       "      <td>610.471680</td>\n",
       "      <td>1298.232544</td>\n",
       "      <td>610.846191</td>\n",
       "      <td>1299.632202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10028</td>\n",
       "      <td>1711.302490</td>\n",
       "      <td>335.212433</td>\n",
       "      <td>1717.384888</td>\n",
       "      <td>341.419952</td>\n",
       "      <td>1722.428955</td>\n",
       "      <td>347.357880</td>\n",
       "      <td>1726.825317</td>\n",
       "      <td>353.189972</td>\n",
       "      <td>1730.555908</td>\n",
       "      <td>...</td>\n",
       "      <td>1742.168213</td>\n",
       "      <td>386.077820</td>\n",
       "      <td>1741.931152</td>\n",
       "      <td>386.440338</td>\n",
       "      <td>1741.685059</td>\n",
       "      <td>386.775360</td>\n",
       "      <td>1741.431641</td>\n",
       "      <td>387.085114</td>\n",
       "      <td>1741.172485</td>\n",
       "      <td>387.371765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003</td>\n",
       "      <td>2127.204346</td>\n",
       "      <td>669.752380</td>\n",
       "      <td>2122.890869</td>\n",
       "      <td>662.372009</td>\n",
       "      <td>2120.180664</td>\n",
       "      <td>656.191040</td>\n",
       "      <td>2118.242920</td>\n",
       "      <td>650.470276</td>\n",
       "      <td>2117.015381</td>\n",
       "      <td>...</td>\n",
       "      <td>2117.430176</td>\n",
       "      <td>625.168640</td>\n",
       "      <td>2117.488770</td>\n",
       "      <td>625.222778</td>\n",
       "      <td>2117.552979</td>\n",
       "      <td>625.284363</td>\n",
       "      <td>2117.621338</td>\n",
       "      <td>625.351379</td>\n",
       "      <td>2117.693115</td>\n",
       "      <td>625.422119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>9897</td>\n",
       "      <td>255.183472</td>\n",
       "      <td>811.148438</td>\n",
       "      <td>254.884674</td>\n",
       "      <td>811.865417</td>\n",
       "      <td>254.695724</td>\n",
       "      <td>812.843689</td>\n",
       "      <td>254.620331</td>\n",
       "      <td>814.127747</td>\n",
       "      <td>254.618958</td>\n",
       "      <td>...</td>\n",
       "      <td>247.922150</td>\n",
       "      <td>888.438538</td>\n",
       "      <td>248.659195</td>\n",
       "      <td>891.403442</td>\n",
       "      <td>249.213135</td>\n",
       "      <td>893.687988</td>\n",
       "      <td>249.519669</td>\n",
       "      <td>895.287903</td>\n",
       "      <td>249.598785</td>\n",
       "      <td>896.309875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>99</td>\n",
       "      <td>578.807251</td>\n",
       "      <td>1136.117554</td>\n",
       "      <td>577.086121</td>\n",
       "      <td>1128.628906</td>\n",
       "      <td>576.118164</td>\n",
       "      <td>1122.508179</td>\n",
       "      <td>575.527588</td>\n",
       "      <td>1117.266113</td>\n",
       "      <td>575.108704</td>\n",
       "      <td>...</td>\n",
       "      <td>568.495239</td>\n",
       "      <td>1086.669922</td>\n",
       "      <td>568.653564</td>\n",
       "      <td>1086.731567</td>\n",
       "      <td>568.830627</td>\n",
       "      <td>1086.807007</td>\n",
       "      <td>569.023376</td>\n",
       "      <td>1086.892334</td>\n",
       "      <td>569.228943</td>\n",
       "      <td>1086.984131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>9905</td>\n",
       "      <td>1757.127197</td>\n",
       "      <td>444.521240</td>\n",
       "      <td>1756.650146</td>\n",
       "      <td>447.238098</td>\n",
       "      <td>1756.043701</td>\n",
       "      <td>449.572723</td>\n",
       "      <td>1755.417480</td>\n",
       "      <td>451.688660</td>\n",
       "      <td>1754.731079</td>\n",
       "      <td>...</td>\n",
       "      <td>1732.925903</td>\n",
       "      <td>472.137390</td>\n",
       "      <td>1731.812866</td>\n",
       "      <td>472.519531</td>\n",
       "      <td>1730.694946</td>\n",
       "      <td>472.903290</td>\n",
       "      <td>1729.570312</td>\n",
       "      <td>473.285431</td>\n",
       "      <td>1728.436768</td>\n",
       "      <td>473.659821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>9910</td>\n",
       "      <td>583.958008</td>\n",
       "      <td>1288.685425</td>\n",
       "      <td>583.229431</td>\n",
       "      <td>1287.101318</td>\n",
       "      <td>582.389709</td>\n",
       "      <td>1285.660278</td>\n",
       "      <td>581.614868</td>\n",
       "      <td>1284.301147</td>\n",
       "      <td>580.901245</td>\n",
       "      <td>...</td>\n",
       "      <td>571.434692</td>\n",
       "      <td>1262.151855</td>\n",
       "      <td>571.103333</td>\n",
       "      <td>1261.875977</td>\n",
       "      <td>570.769592</td>\n",
       "      <td>1261.672485</td>\n",
       "      <td>570.431641</td>\n",
       "      <td>1261.539551</td>\n",
       "      <td>570.087463</td>\n",
       "      <td>1261.475098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>9918</td>\n",
       "      <td>583.601379</td>\n",
       "      <td>1154.699829</td>\n",
       "      <td>582.889221</td>\n",
       "      <td>1147.027222</td>\n",
       "      <td>581.786011</td>\n",
       "      <td>1141.269287</td>\n",
       "      <td>580.978577</td>\n",
       "      <td>1136.248169</td>\n",
       "      <td>580.182129</td>\n",
       "      <td>...</td>\n",
       "      <td>568.439148</td>\n",
       "      <td>1102.976562</td>\n",
       "      <td>568.402588</td>\n",
       "      <td>1102.971069</td>\n",
       "      <td>568.383728</td>\n",
       "      <td>1102.979492</td>\n",
       "      <td>568.380676</td>\n",
       "      <td>1102.999268</td>\n",
       "      <td>568.391602</td>\n",
       "      <td>1103.028076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID           v1           v2           v3           v4           v5  \\\n",
       "0     10002  1718.167358   349.451019  1721.188354   355.049988  1723.683105   \n",
       "1     10015   728.643372  1227.529663   726.557922  1223.242310   724.897827   \n",
       "2     10019   585.184998  1249.893677   586.643433  1251.096802   587.839905   \n",
       "3     10028  1711.302490   335.212433  1717.384888   341.419952  1722.428955   \n",
       "4      1003  2127.204346   669.752380  2122.890869   662.372009  2120.180664   \n",
       "...     ...          ...          ...          ...          ...          ...   \n",
       "3195   9897   255.183472   811.148438   254.884674   811.865417   254.695724   \n",
       "3196     99   578.807251  1136.117554   577.086121  1128.628906   576.118164   \n",
       "3197   9905  1757.127197   444.521240  1756.650146   447.238098  1756.043701   \n",
       "3198   9910   583.958008  1288.685425   583.229431  1287.101318   582.389709   \n",
       "3199   9918   583.601379  1154.699829   582.889221  1147.027222   581.786011   \n",
       "\n",
       "               v6           v7           v8           v9  ...          v51  \\\n",
       "0      359.964111  1725.946655   364.665222  1728.003052  ...  1706.635620   \n",
       "1     1219.611206   723.590637  1216.297607   722.560852  ...   712.900696   \n",
       "2     1252.356201   588.974243  1253.730713   590.088745  ...   609.061584   \n",
       "3      347.357880  1726.825317   353.189972  1730.555908  ...  1742.168213   \n",
       "4      656.191040  2118.242920   650.470276  2117.015381  ...  2117.430176   \n",
       "...           ...          ...          ...          ...  ...          ...   \n",
       "3195   812.843689   254.620331   814.127747   254.618958  ...   247.922150   \n",
       "3196  1122.508179   575.527588  1117.266113   575.108704  ...   568.495239   \n",
       "3197   449.572723  1755.417480   451.688660  1754.731079  ...  1732.925903   \n",
       "3198  1285.660278   581.614868  1284.301147   580.901245  ...   571.434692   \n",
       "3199  1141.269287   580.978577  1136.248169   580.182129  ...   568.439148   \n",
       "\n",
       "              v52          v53          v54          v55          v56  \\\n",
       "0      418.986298  1705.698486   419.561737  1704.978638   420.018860   \n",
       "1     1164.670898   712.451050  1163.398804   712.058411  1162.318481   \n",
       "2     1293.652100   609.576538  1295.245361   610.047302  1296.771484   \n",
       "3      386.077820  1741.931152   386.440338  1741.685059   386.775360   \n",
       "4      625.168640  2117.488770   625.222778  2117.552979   625.284363   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "3195   888.438538   248.659195   891.403442   249.213135   893.687988   \n",
       "3196  1086.669922   568.653564  1086.731567   568.830627  1086.807007   \n",
       "3197   472.137390  1731.812866   472.519531  1730.694946   472.903290   \n",
       "3198  1262.151855   571.103333  1261.875977   570.769592  1261.672485   \n",
       "3199  1102.976562   568.402588  1102.971069   568.383728  1102.979492   \n",
       "\n",
       "              v57          v58          v59          v60  \n",
       "0     1704.442505   420.376678  1704.054443   420.654175  \n",
       "1      711.713684  1161.396240   711.416321  1160.611816  \n",
       "2      610.471680  1298.232544   610.846191  1299.632202  \n",
       "3     1741.431641   387.085114  1741.172485   387.371765  \n",
       "4     2117.621338   625.351379  2117.693115   625.422119  \n",
       "...           ...          ...          ...          ...  \n",
       "3195   249.519669   895.287903   249.598785   896.309875  \n",
       "3196   569.023376  1086.892334   569.228943  1086.984131  \n",
       "3197  1729.570312   473.285431  1728.436768   473.659821  \n",
       "3198   570.431641  1261.539551   570.087463  1261.475098  \n",
       "3199   568.380676  1102.999268   568.391602  1103.028076  \n",
       "\n",
       "[3200 rows x 61 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ID'] = submission['ID']\n",
    "cols = df.columns[-1:].tolist() + df.columns[:-1].tolist()\n",
    "df = df[cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def save_submission(df, filename):\n",
    "    filename = filename + \"_\" + str(datetime.now()) + \".csv\"\n",
    "    file_path = os.path.join(submission_dir, filename)\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submission(df, \"stacked LSTM + Social(num_neighbors) + relave_position + epoch20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
